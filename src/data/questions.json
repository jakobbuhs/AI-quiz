[
  {
    "question": "Which of the following is MOST clearly a classification task?",
    "options": [
      "Predicting the price of a used car",
      "Predicting whether a customer will churn or not",
      "Estimating tomorrow's temperature in degrees",
      "Estimating the number of items sold next week"
    ],
    "correct": "Predicting whether a customer will churn or not",
    "explanation": "Customer churn prediction has discrete outcomes (churn / not churn), which is typical for classification.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which of the following is MOST clearly a regression task?",
    "options": [
      "Predicting whether an email is spam",
      "Predicting which product a user will click",
      "Predicting the total amount a customer will spend next month",
      "Grouping customers into segments"
    ],
    "correct": "Predicting the total amount a customer will spend next month",
    "explanation": "The output is a continuous numeric value, which is characteristic of regression problems.",
    "topic": "Regression Models"
  },
  {
    "question": "A multi-class classification model is one that:",
    "options": [
      "Can only distinguish between two classes",
      "Can assign one example to one of three or more possible classes",
      "Always assigns multiple labels to each example",
      "Only works with numeric labels"
    ],
    "correct": "Can assign one example to one of three or more possible classes",
    "explanation": "Multi-class classification handles more than two mutually exclusive classes.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which description best fits a multi-label classification problem?",
    "options": [
      "Each example belongs to exactly one of two classes",
      "Each example belongs to exactly one class out of many",
      "Each example can be associated with zero, one, or several labels simultaneously",
      "Labels are continuous rather than discrete"
    ],
    "correct": "Each example can be associated with zero, one, or several labels simultaneously",
    "explanation": "Multi-label tasks allow multiple labels to be true for the same instance, such as movie genres.",
    "topic": "Supervised Learning"
  },
  {
    "question": "In sentiment analysis of product reviews, labels such as 'negative', 'neutral', and 'positive' indicate:",
    "options": [
      "A regression problem",
      "A clustering problem",
      "A multi-class classification problem",
      "A sequence prediction problem"
    ],
    "correct": "A multi-class classification problem",
    "explanation": "There are three possible categorical outcomes and each review gets exactly one label.",
    "topic": "AI Applications"
  },
  {
    "question": "Which is the BEST example of an AI application in healthcare?",
    "options": [
      "A spreadsheet summing patient bills",
      "A rule that prints 'hello' every morning",
      "An ML model that analyzes radiology images to detect tumors",
      "A PDF viewer for medical reports"
    ],
    "correct": "An ML model that analyzes radiology images to detect tumors",
    "explanation": "Using ML to analyze medical images is a widely studied AI application in healthcare.",
    "topic": "AI Applications"
  },
  {
    "question": "Which task is MOST suitable for computer vision?",
    "options": [
      "Predicting the next word in a sentence",
      "Detecting objects in traffic camera images",
      "Calculating compound interest",
      "Parsing programming languages"
    ],
    "correct": "Detecting objects in traffic camera images",
    "explanation": "Computer vision deals with understanding and analyzing visual data such as images or video.",
    "topic": "AI Applications"
  },
  {
    "question": "Which task is MOST suitable for natural language processing (NLP)?",
    "options": [
      "Clustering customers by location",
      "Translating a document from English to German",
      "Recognizing faces in a photo",
      "Detecting anomalies in sensor data"
    ],
    "correct": "Translating a document from English to German",
    "explanation": "Machine translation is a classic NLP task that focuses on understanding and generating text.",
    "topic": "AI Applications"
  },
  {
    "question": "Which step usually comes directly AFTER collecting raw data in an AI pipeline?",
    "options": [
      "Deploying the model to production",
      "Exploratory data analysis and cleaning",
      "Selecting evaluation metrics",
      "Writing user documentation"
    ],
    "correct": "Exploratory data analysis and cleaning",
    "explanation": "After data collection, you typically explore, clean, and preprocess the data before modeling.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which of the following is MOST likely a data quality issue?",
    "options": [
      "Using CSV instead of JSON",
      "Duplicated records with inconsistent labels",
      "Having many features",
      "Having separate train and test sets"
    ],
    "correct": "Duplicated records with inconsistent labels",
    "explanation": "Conflicting labels for identical examples are a serious data quality problem.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "The term 'feature' in machine learning refers to:",
    "options": [
      "The loss function",
      "A single input variable used by the model",
      "The model output",
      "The evaluation metric"
    ],
    "correct": "A single input variable used by the model",
    "explanation": "Features are measurable properties or characteristics used as inputs to models.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "The term 'label' in supervised learning refers to:",
    "options": [
      "A special input feature",
      "The true output or target value for each example",
      "The learning rate parameter",
      "The predicted output of the model"
    ],
    "correct": "The true output or target value for each example",
    "explanation": "Labels provide the ground truth that models learn to predict from inputs.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "In a dataset of apartment prices, which is MOST likely a label in a supervised learning setup?",
    "options": [
      "Number of rooms",
      "Size in square meters",
      "Neighborhood code",
      "Final sale price"
    ],
    "correct": "Final sale price",
    "explanation": "The sale price is the outcome we want to predict; features describe the apartment.",
    "topic": "Regression Models"
  },
  {
    "question": "Which statement about supervised and unsupervised learning is TRUE?",
    "options": [
      "Supervised learning uses labels; unsupervised does not",
      "Unsupervised learning always performs better",
      "Supervised learning is only used for images",
      "Unsupervised learning is only used for text"
    ],
    "correct": "Supervised learning uses labels; unsupervised does not",
    "explanation": "The main distinction is whether labeled target values are available for training.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Clustering customer transaction data without known customer segments is an example of:",
    "options": [
      "Supervised learning",
      "Unsupervised learning",
      "Reinforcement learning",
      "Semi-supervised learning"
    ],
    "correct": "Unsupervised learning",
    "explanation": "Without labels and with a goal to discover structure, clustering is unsupervised.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Which algorithm is MOST commonly associated with clustering?",
    "options": [
      "k-means",
      "Logistic regression",
      "Linear regression",
      "Naive Bayes"
    ],
    "correct": "k-means",
    "explanation": "k-means is a widely used clustering algorithm for partitioning data into k groups.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Which of the following is a MAIN limitation of k-means clustering?",
    "options": [
      "It cannot handle numeric features",
      "It assumes clusters are roughly spherical and similar in size",
      "It cannot scale to large datasets",
      "It requires labeled data"
    ],
    "correct": "It assumes clusters are roughly spherical and similar in size",
    "explanation": "k-means works best when clusters are fairly compact and similar in scale.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Which task is a good candidate for anomaly detection?",
    "options": [
      "Predicting tomorrow's weather",
      "Grouping news articles by topic",
      "Finding unusual credit card transactions that might indicate fraud",
      "Translating between languages"
    ],
    "correct": "Finding unusual credit card transactions that might indicate fraud",
    "explanation": "Anomaly detection aims to identify rare, unusual events that deviate from normal patterns.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Which statement about anomaly detection models is TRUE?",
    "options": [
      "They usually require labels for all anomalies",
      "They can often be trained using only examples of normal behavior",
      "They only work on text data",
      "They require deep reinforcement learning"
    ],
    "correct": "They can often be trained using only examples of normal behavior",
    "explanation": "Many anomaly detectors learn normal patterns and flag deviations as anomalies.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Which of the following is a common reason to use dimensionality reduction?",
    "options": [
      "To increase memory usage",
      "To deliberately overfit the model",
      "To reduce noise and simplify models by removing redundant features",
      "To convert categorical features into numerical ones"
    ],
    "correct": "To reduce noise and simplify models by removing redundant features",
    "explanation": "Reducing dimensionality can help denoise data and improve model performance or interpretability.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Principal Component Analysis (PCA) is typically used to:",
    "options": [
      "Cluster data into k groups",
      "Perform supervised classification",
      "Project data into a lower-dimensional space capturing maximum variance",
      "Label unlabeled data"
    ],
    "correct": "Project data into a lower-dimensional space capturing maximum variance",
    "explanation": "PCA finds directions (components) that explain the most variance in the data.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which scenario BEST illustrates concept drift?",
    "options": [
      "Measuring gravity in a physics laboratory",
      "Predicting movie ratings with no change in user preferences",
      "Predicting online ad clicks when user interests change over time",
      "Using a constant mapping from input to output"
    ],
    "correct": "Predicting online ad clicks when user interests change over time",
    "explanation": "When user behavior evolves, the relationship between inputs and labels changes, causing concept drift.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Data drift is BEST described as:",
    "options": [
      "Changes in the model architecture",
      "Changes in the distribution of input features over time",
      "A bug in the loss function",
      "A sudden improvement in accuracy"
    ],
    "correct": "Changes in the distribution of input features over time",
    "explanation": "Data drift refers to a shift in the input data distribution compared to training data.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which approach can help address data drift in production?",
    "options": [
      "Never retraining the model",
      "Regularly monitoring data and retraining with updated data",
      "Turning off logging to reduce overhead",
      "Reducing the number of features to one"
    ],
    "correct": "Regularly monitoring data and retraining with updated data",
    "explanation": "Continuous monitoring and periodic retraining are standard ways to handle drift.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which is an example of a non-functional requirement for an AI system?",
    "options": [
      "The model should achieve at least 90% accuracy",
      "The model should use gradient descent",
      "The prediction latency must be under 100 milliseconds",
      "The model must be a decision tree"
    ],
    "correct": "The prediction latency must be under 100 milliseconds",
    "explanation": "Latency is a non-functional requirement about system performance, not about the function or algorithm itself.",
    "topic": "AI Applications"
  },
  {
    "question": "Which is an example of a functional requirement for an AI application?",
    "options": [
      "The system must respond within 200 ms",
      "The system must classify incoming emails as spam or not spam",
      "The system must use a GPU",
      "The system must consume less than 1GB of RAM"
    ],
    "correct": "The system must classify incoming emails as spam or not spam",
    "explanation": "Functional requirements describe what the system should do, such as performing spam classification.",
    "topic": "AI Applications"
  },
  {
    "question": "Which metric is commonly used to measure the quality of a clustering result when labels are NOT available?",
    "options": [
      "Accuracy",
      "Silhouette score",
      "Precision",
      "Recall"
    ],
    "correct": "Silhouette score",
    "explanation": "The silhouette score measures how similar an object is to its own cluster compared to other clusters.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Which metric would you typically use to measure an anomaly detection model where anomalies are rare and labeled?",
    "options": [
      "Accuracy only",
      "Precision and recall (or F1-score) for the anomaly class",
      "Mean squared error only",
      "Silhouette score"
    ],
    "correct": "Precision and recall (or F1-score) for the anomaly class",
    "explanation": "When the positive class (anomalies) is rare, precision, recall, and F1-score provide more insight than accuracy.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "In a confusion matrix, true negatives (TN) correspond to:",
    "options": [
      "Correctly predicted positive cases",
      "Correctly predicted negative cases",
      "Incorrectly predicted positive cases",
      "Incorrectly predicted negative cases"
    ],
    "correct": "Correctly predicted negative cases",
    "explanation": "TN are negative examples that the model correctly predicted as negative.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which of the following is a typical property of linear regression?",
    "options": [
      "It models nonlinear decision boundaries only",
      "It assumes a linear relationship between features and target",
      "It can only output values between 0 and 1",
      "It always uses a sigmoid activation"
    ],
    "correct": "It assumes a linear relationship between features and target",
    "explanation": "Linear regression models the target as a linear combination of input features.",
    "topic": "Regression Models"
  },
  {
    "question": "R-squared (coefficient of determination) is commonly used to:",
    "options": [
      "Evaluate classification models",
      "Measure the variance explained by a regression model",
      "Compute class probabilities",
      "Select the number of clusters"
    ],
    "correct": "Measure the variance explained by a regression model",
    "explanation": "R-squared indicates how well the regression model explains variance in the target variable.",
    "topic": "Regression Models"
  },
  {
    "question": "What does a very low R-squared value suggest about a regression model?",
    "options": [
      "The model explains little of the variability in the target",
      "The model is perfectly accurate",
      "The model is guaranteed to be unbiased",
      "The model is always overfitting"
    ],
    "correct": "The model explains little of the variability in the target",
    "explanation": "Low R-squared means the model's predictions do not capture much of the variation in the target.",
    "topic": "Regression Models"
  },
  {
    "question": "Which model is typically used to estimate the probability of a binary outcome?",
    "options": [
      "Linear regression",
      "Logistic regression",
      "k-means clustering",
      "ARIMA"
    ],
    "correct": "Logistic regression",
    "explanation": "Logistic regression models log-odds and outputs probabilities between 0 and 1.",
    "topic": "Regression Models"
  },
  {
    "question": "Which of the following is TRUE about logistic regression?",
    "options": [
      "It predicts continuous numeric values",
      "It is mainly used for clustering",
      "It is commonly used for binary classification tasks",
      "It cannot output probabilities"
    ],
    "correct": "It is commonly used for binary classification tasks",
    "explanation": "Logistic regression is a linear model suitable for classifying inputs into two classes.",
    "topic": "Regression Models"
  },
  {
    "question": "Which of these is a reason to prefer a simpler model over a more complex one, given similar performance?",
    "options": [
      "Simpler models are always slower",
      "Simpler models are usually harder to interpret",
      "Simpler models tend to generalize better and are easier to explain",
      "Complex models cannot overfit"
    ],
    "correct": "Simpler models tend to generalize better and are easier to explain",
    "explanation": "Occam's razor suggests preferring simpler models that are easier to maintain and interpret.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which term describes the practice of repeatedly training models with different hyperparameters to find the best one?",
    "options": [
      "Feature engineering",
      "Hyperparameter tuning",
      "Regularization",
      "Normalization"
    ],
    "correct": "Hyperparameter tuning",
    "explanation": "Hyperparameter tuning explores different configurations to optimize model performance.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Grid search and random search are methods for:",
    "options": [
      "Feature scaling",
      "Hyperparameter optimization",
      "Label encoding",
      "Data anonymization"
    ],
    "correct": "Hyperparameter optimization",
    "explanation": "Grid and random search systematically or randomly explore combinations of hyperparameters.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which statement about random search vs grid search is often TRUE?",
    "options": [
      "Random search always checks fewer configurations",
      "Random search can be more efficient than grid search in high-dimensional hyperparameter spaces",
      "Grid search always finds better models",
      "Grid search is random, random search is systematic"
    ],
    "correct": "Random search can be more efficient than grid search in high-dimensional hyperparameter spaces",
    "explanation": "Random search explores hyperparameter space more broadly when many dimensions are involved.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which approach can help reduce overfitting in a deep neural network?",
    "options": [
      "Using a larger model with more parameters",
      "Training for many more epochs without monitoring",
      "Applying dropout and using more data",
      "Removing the validation set"
    ],
    "correct": "Applying dropout and using more data",
    "explanation": "Dropout and additional training data are classic methods to improve generalization.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which of the following is NOT typically a hyperparameter of a neural network?",
    "options": [
      "Number of hidden layers",
      "Learning rate",
      "Batch size",
      "Model's learned weight values"
    ],
    "correct": "Model's learned weight values",
    "explanation": "Weights are learned from data; hyperparameters are set before training.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which part of a neural network is updated during backpropagation?",
    "options": [
      "Only the input data",
      "The loss function definition",
      "The weights and biases of the model",
      "The training labels"
    ],
    "correct": "The weights and biases of the model",
    "explanation": "Backpropagation computes gradients and adjusts trainable parameters to minimize loss.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which learning rate behavior is generally desirable during training?",
    "options": [
      "A learning rate that is extremely large and constant",
      "A learning rate that decreases over time to help fine-tune the model",
      "A learning rate that is always zero",
      "A learning rate that changes randomly every batch"
    ],
    "correct": "A learning rate that decreases over time to help fine-tune the model",
    "explanation": "Higher learning rates early and smaller rates later can help converge more smoothly.",
    "topic": "Deep Learning"
  },
  {
    "question": "In convolutional neural networks, pooling layers are primarily used to:",
    "options": [
      "Increase the resolution of the image",
      "Reduce spatial dimensions and extract dominant features",
      "Convert images to text",
      "Compute the loss function"
    ],
    "correct": "Reduce spatial dimensions and extract dominant features",
    "explanation": "Pooling reduces the size of feature maps and provides translational invariance.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which is a typical activation function used in hidden layers of deep networks?",
    "options": [
      "Softmax",
      "ReLU",
      "Linear identity only",
      "Euclidean distance"
    ],
    "correct": "ReLU",
    "explanation": "ReLU is commonly used thanks to its simplicity and effectiveness for deep networks.",
    "topic": "Deep Learning"
  },
  {
    "question": "Softmax activation is most commonly used in:",
    "options": [
      "Hidden layers of regression models",
      "Output layer of multi-class classification networks",
      "Input normalization",
      "Clustering algorithms"
    ],
    "correct": "Output layer of multi-class classification networks",
    "explanation": "Softmax converts logits into probabilities over several classes.",
    "topic": "Deep Learning"
  },
  {
    "question": "In NLP, a 'vocabulary' typically refers to:",
    "options": [
      "All sentences in the corpus",
      "The set of distinct tokens (e.g., words or subwords) used by the model",
      "All documents in a dataset",
      "All possible topics"
    ],
    "correct": "The set of distinct tokens (e.g., words or subwords) used by the model",
    "explanation": "The vocabulary defines the mapping from tokens to IDs used in training and inference.",
    "topic": "AI Applications"
  },
  {
    "question": "Which of the following is a typical pre-processing step for text data?",
    "options": [
      "Image augmentation",
      "Tokenization and lowercasing",
      "Fourier transform",
      "Histogram equalization"
    ],
    "correct": "Tokenization and lowercasing",
    "explanation": "Tokenization and normalization such as lowercasing are standard steps in text preprocessing.",
    "topic": "AI Applications"
  },
  {
    "question": "Which of these is a common risk when using AI for automated hiring decisions?",
    "options": [
      "The model will always be perfectly fair",
      "The model may learn and amplify historical hiring biases",
      "The model will refuse to make any prediction",
      "The model will ignore all input data"
    ],
    "correct": "The model may learn and amplify historical hiring biases",
    "explanation": "If historical data is biased, the AI system can perpetuate or exacerbate that bias.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which practice can improve fairness in a hiring model?",
    "options": [
      "Relying only on historical labels",
      "Ignoring all evaluation metrics",
      "Auditing datasets for bias and including fairness constraints in training",
      "Reducing dataset size drastically"
    ],
    "correct": "Auditing datasets for bias and including fairness constraints in training",
    "explanation": "Assessing biases and designing fairness-aware training help mitigate unfair outcomes.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which statement about AI transparency is correct?",
    "options": [
      "It is never required in real systems",
      "Transparent systems make their behavior and limitations understandable to stakeholders",
      "Transparency means publishing all source code",
      "Transparency guarantees no errors will occur"
    ],
    "correct": "Transparent systems make their behavior and limitations understandable to stakeholders",
    "explanation": "Transparency is about clarity of operation, not necessarily full code disclosure.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which term describes a human's tendency to trust AI decisions more than they should?",
    "options": [
      "Automation bias",
      "Data drift",
      "Overfitting",
      "Clustering"
    ],
    "correct": "Automation bias",
    "explanation": "Automation bias is the over-reliance on automated decision systems, even when they are wrong.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Why is documentation important in AI projects?",
    "options": [
      "It replaces evaluation metrics",
      "It makes experiments impossible to reproduce",
      "It helps others understand data, methods, and limitations of the system",
      "It is only needed for legal reasons"
    ],
    "correct": "It helps others understand data, methods, and limitations of the system",
    "explanation": "Good documentation supports transparency, maintenance, and responsible use.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which of the following is an example of a data preprocessing pipeline step?",
    "options": [
      "Choosing hyperparameters",
      "Scaling numeric features and encoding categorical variables",
      "Deploying the model",
      "Monitoring model drift"
    ],
    "correct": "Scaling numeric features and encoding categorical variables",
    "explanation": "Transforming and preparing input features is a core part of preprocessing pipelines.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which is a common data engineering challenge for AI systems?",
    "options": [
      "Having too many GPUs",
      "Ensuring data flows reliably from source systems to the model with correct formats",
      "Having too clear documentation",
      "Avoiding logging"
    ],
    "correct": "Ensuring data flows reliably from source systems to the model with correct formats",
    "explanation": "Data engineering deals with building robust pipelines to feed clean data into AI models.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which of these best describes MLOps?",
    "options": [
      "Only tuning hyperparameters",
      "Applying DevOps principles to the machine learning lifecycle",
      "A type of neural network",
      "An unsupervised learning algorithm"
    ],
    "correct": "Applying DevOps principles to the machine learning lifecycle",
    "explanation": "MLOps focuses on automation, reproducibility, and monitoring across ML development and deployment.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which is a benefit of using version control for data and models?",
    "options": [
      "You never need backups",
      "It prevents any changes",
      "It enables reproducibility and traceability of experiments",
      "It guarantees fairness"
    ],
    "correct": "It enables reproducibility and traceability of experiments",
    "explanation": "Versioning helps track which data and models created which results.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which risk is associated with using black-box models for loan approval decisions?",
    "options": [
      "They are always too slow",
      "They may be impossible to explain to regulators and applicants",
      "They cannot achieve high accuracy",
      "They cannot handle numeric features"
    ],
    "correct": "They may be impossible to explain to regulators and applicants",
    "explanation": "Financial regulation often requires clear explanations of why a loan was approved or denied.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which technique can provide local explanations for a single model prediction?",
    "options": [
      "Train-test split",
      "k-means clustering",
      "LIME (Local Interpretable Model-agnostic Explanations)",
      "Batch normalization"
    ],
    "correct": "LIME (Local Interpretable Model-agnostic Explanations)",
    "explanation": "LIME approximates a complex model locally with a simpler, interpretable model.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which is a potential downside of using very large language models in production?",
    "options": [
      "They never produce incorrect information",
      "They require no computational resources",
      "They can be expensive to run and may hallucinate incorrect facts",
      "They cannot be fine-tuned"
    ],
    "correct": "They can be expensive to run and may hallucinate incorrect facts",
    "explanation": "LLMs often need significant compute and can generate plausible but wrong outputs.",
    "topic": "Generative AI"
  },
  {
    "question": "Which statement about hallucinations in large language models is TRUE?",
    "options": [
      "They refer to hardware failures",
      "They mean the model refuses to answer any question",
      "They are confident-sounding but factually incorrect outputs",
      "They occur only when the model is not trained"
    ],
    "correct": "They are confident-sounding but factually incorrect outputs",
    "explanation": "Hallucinations are a known issue where models invent details without evidence.",
    "topic": "Generative AI"
  },
  {
    "question": "Which is a typical safeguard when deploying a generative text model in a customer-facing chatbot?",
    "options": [
      "No monitoring at all",
      "Allowing the model to respond with any content",
      "Adding content filters, guardrails, and human review for high-risk cases",
      "Disabling logging"
    ],
    "correct": "Adding content filters, guardrails, and human review for high-risk cases",
    "explanation": "Safety measures reduce the risk of inappropriate or harmful responses.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which situation is MOST likely to create a feedback loop in an AI system?",
    "options": [
      "Using static training data only once",
      "Model decisions influence future data, which is then used to retrain the model",
      "Deploying the model without any users",
      "Training with fully random data"
    ],
    "correct": "Model decisions influence future data, which is then used to retrain the model",
    "explanation": "Feedback loops arise when model outputs impact future inputs, potentially reinforcing biases.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "In recommender systems, 'filter bubble' refers to:",
    "options": [
      "A method for cleaning data",
      "A phenomenon where users only see content similar to what they already like",
      "A technique for filtering spam",
      "A clustering algorithm"
    ],
    "correct": "A phenomenon where users only see content similar to what they already like",
    "explanation": "Filter bubbles can reduce exposure to diverse information and perspectives.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which approach can help mitigate filter bubbles?",
    "options": [
      "Only showing highly personalized recommendations",
      "Occasionally injecting diverse or exploratory content into recommendations",
      "Removing all recommendations",
      "Ignoring user feedback"
    ],
    "correct": "Occasionally injecting diverse or exploratory content into recommendations",
    "explanation": "Diversity-aware recommendation strategies can reduce filter bubble effects.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which of the following best describes collaborative filtering in recommender systems?",
    "options": [
      "Recommending items based only on item metadata",
      "Recommending items based on what similar users liked",
      "Recommending items randomly",
      "Recommending only the most expensive items"
    ],
    "correct": "Recommending items based on what similar users liked",
    "explanation": "Collaborative filtering finds patterns in user-item interactions to suggest items.",
    "topic": "AI Applications"
  },
  {
    "question": "Content-based recommendation primarily uses:",
    "options": [
      "Other users' ratings without item attributes",
      "The textual or feature-based description of items a user liked",
      "Random sampling of items",
      "Only price information"
    ],
    "correct": "The textual or feature-based description of items a user liked",
    "explanation": "Content-based systems recommend items with similar characteristics to those previously liked.",
    "topic": "AI Applications"
  },
  {
    "question": "Which metric is commonly used to evaluate recommender systems offline?",
    "options": [
      "Mean average precision or hit rate",
      "Silhouette score",
      "R-squared",
      "Cross-entropy loss only"
    ],
    "correct": "Mean average precision or hit rate",
    "explanation": "Ranking metrics like MAP or hit rate are standard for evaluating top-N recommendation quality.",
    "topic": "AI Applications"
  },
  {
    "question": "Which scenario best illustrates reinforcement learning in an online service?",
    "options": [
      "Clustering users once per year",
      "Training a static classifier for spam detection",
      "An agent adapting which news articles to show based on click feedback",
      "Predicting tomorrow's sales from historical data"
    ],
    "correct": "An agent adapting which news articles to show based on click feedback",
    "explanation": "RL agents choose actions to maximize long-term reward, such as user engagement.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "Which is a typical difference between supervised learning and reinforcement learning?",
    "options": [
      "RL uses labeled examples; supervised does not",
      "RL learns from trial-and-error interactions and reward signals, not direct labels for each state",
      "Supervised learning only works with images",
      "RL only works in offline settings"
    ],
    "correct": "RL learns from trial-and-error interactions and reward signals, not direct labels for each state",
    "explanation": "In RL, the agent explores and receives feedback through rewards instead of explicit labels for each example.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "Which factor can make reinforcement learning difficult to deploy in the real world?",
    "options": [
      "It always requires labels",
      "Exploration can be risky or costly in real environments",
      "It never learns optimal policies",
      "It cannot model sequential decisions"
    ],
    "correct": "Exploration can be risky or costly in real environments",
    "explanation": "Trying new actions to explore can cause harm or costly mistakes in real-world systems.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "Which of these is an example of a sequential decision-making problem?",
    "options": [
      "Predicting a single house price",
      "Choosing the next ad to show a user at each page view",
      "Clustering users into groups once",
      "Predicting one-off exam grades"
    ],
    "correct": "Choosing the next ad to show a user at each page view",
    "explanation": "Sequential decisions consider how current actions affect future states and rewards.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "Which is a main reason to log inputs and outputs of AI systems in production?",
    "options": [
      "To reduce disk usage",
      "To ensure models cannot be updated",
      "To enable monitoring, debugging, and future retraining using real data",
      "To hide system behavior from auditors"
    ],
    "correct": "To enable monitoring, debugging, and future retraining using real data",
    "explanation": "Logs are vital for understanding behavior, diagnosing issues, and improving models.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Why is it important to carefully manage access to production AI logs?",
    "options": [
      "They never contain sensitive information",
      "They might contain personal or confidential data that must be protected",
      "They cannot be analyzed",
      "They are always encrypted by default"
    ],
    "correct": "They might contain personal or confidential data that must be protected",
    "explanation": "Logs can include sensitive information, so access control and privacy safeguards are essential.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which term describes a system that combines human decision-makers and AI models to achieve better performance than either alone?",
    "options": [
      "Human-in-the-loop system",
      "Fully autonomous system",
      "Rule-based system",
      "Static pipeline"
    ],
    "correct": "Human-in-the-loop system",
    "explanation": "Human-in-the-loop designs leverage both AI and human expertise for more robust decisions.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which is a typical advantage of keeping a human in the loop for high-stakes AI decisions?",
    "options": [
      "Humans always make perfect decisions",
      "It removes the need for documentation",
      "Humans can catch obvious errors and provide contextual judgment",
      "It eliminates the need for model testing"
    ],
    "correct": "Humans can catch obvious errors and provide contextual judgment",
    "explanation": "Human oversight can mitigate model failures and consider additional context.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which describes the main goal of responsible AI?",
    "options": [
      "Maximizing accuracy regardless of consequences",
      "Deploying as many AI systems as possible",
      "Ensuring AI systems are ethical, fair, transparent, and aligned with human values",
      "Removing all humans from decision-making"
    ],
    "correct": "Ensuring AI systems are ethical, fair, transparent, and aligned with human values",
    "explanation": "Responsible AI emphasizes the broader societal impact beyond technical performance.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which scenario is MOST likely to raise privacy concerns in an AI project?",
    "options": [
      "Using fully synthetic, non-identifiable data",
      "Using aggregate statistics with no individual detail",
      "Using detailed location traces and identities of users without their consent",
      "Using weather data from a public API"
    ],
    "correct": "Using detailed location traces and identities of users without their consent",
    "explanation": "Detailed, identifiable personal data without consent is a major privacy issue.",
    "topic": "AI Ethics and Explainability"
  }, 
  {
    "question": "Which of the following is a typical FIRST step in an AI project?",
    "options": [
      "Choose the neural network architecture",
      "Collect any data you can find",
      "Define the problem and success criteria clearly",
      "Deploy a baseline model to production"
    ],
    "correct": "Define the problem and success criteria clearly",
    "explanation": "Before collecting data or training models, you must understand the business problem and define what success looks like.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which question is MOST appropriate when scoping an AI use case?",
    "options": [
      "Which GPU brand should we buy?",
      "How many hidden layers will our model have?",
      "How will we measure if the model solves the user’s problem?",
      "Which cloud provider has the cheapest storage?"
    ],
    "correct": "How will we measure if the model solves the user’s problem?",
    "explanation": "Scoping focuses on defining objectives and metrics, not technical details like GPUs or cloud providers.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "What is the main purpose of exploratory data analysis (EDA) in an AI project?",
    "options": [
      "To finalize the model architecture",
      "To understand data quality, distributions, and potential issues",
      "To tune hyperparameters",
      "To deploy the model to production"
    ],
    "correct": "To understand data quality, distributions, and potential issues",
    "explanation": "EDA helps you familiarize yourself with the data, detect anomalies, and guide later modeling decisions.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which of the following is usually inspected during exploratory data analysis?",
    "options": [
      "GPU temperature logs",
      "CPU cache sizes",
      "Distributions of features and missing values",
      "Production latency metrics"
    ],
    "correct": "Distributions of features and missing values",
    "explanation": "EDA typically involves inspecting feature distributions, missingness, and correlations.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "What is a typical risk of manually inspecting only a small subset of a large dataset?",
    "options": [
      "You will find too many patterns",
      "You may miss rare but important cases or biases",
      "You cannot compute averages",
      "You cannot train a model afterwards"
    ],
    "correct": "You may miss rare but important cases or biases",
    "explanation": "Small samples may not represent the full distribution, causing you to overlook important edge cases.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which type of data issue is most likely to cause problems when training a supervised model?",
    "options": [
      "High-resolution images",
      "Inconsistent labels for similar examples",
      "Multiple features per example",
      "Using a CSV format instead of JSON"
    ],
    "correct": "Inconsistent labels for similar examples",
    "explanation": "Label noise makes learning the true mapping harder and can significantly reduce model performance.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "What does it usually mean if your model performs very well on both the training and validation sets?",
    "options": [
      "The model is probably overfitting",
      "The model may be underfitting",
      "The model generalizes well to similar data",
      "The dataset is too small to train any model"
    ],
    "correct": "The model generalizes well to similar data",
    "explanation": "Strong performance on both train and validation typically indicates good generalization (assuming no leakage).",
    "topic": "ML Fundamentals"
  },
  {
    "question": "If your model has low training error but high validation error, what does this suggest?",
    "options": [
      "Underfitting",
      "Overfitting",
      "Perfect generalization",
      "Data leakage"
    ],
    "correct": "Overfitting",
    "explanation": "The model has learned the training data too well but fails to generalize to unseen validation data.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which of the following can help mitigate underfitting?",
    "options": [
      "Using a simpler model",
      "Reducing the number of training examples",
      "Increasing model complexity or adding more informative features",
      "Adding stronger regularization"
    ],
    "correct": "Increasing model complexity or adding more informative features",
    "explanation": "Underfitting means the model is too simple; more complexity or better features can help capture the pattern.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "What is regularization in machine learning?",
    "options": [
      "A method to perfectly fit the training data",
      "A technique to penalize model complexity to reduce overfitting",
      "A method to generate synthetic data",
      "A way to increase the number of layers in a network"
    ],
    "correct": "A technique to penalize model complexity to reduce overfitting",
    "explanation": "Regularization discourages overly complex models, helping them generalize better.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "L2 regularization in linear models primarily:",
    "options": [
      "Encourages weights to be exactly zero",
      "Penalizes large weights by their squared magnitude",
      "Increases the learning rate",
      "Changes the labels in the dataset"
    ],
    "correct": "Penalizes large weights by their squared magnitude",
    "explanation": "L2 adds a penalty proportional to the sum of squared weights, shrinking them but rarely to zero.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which statement about L1 regularization is correct?",
    "options": [
      "It often produces sparse models with many weights exactly zero",
      "It always increases model complexity",
      "It cannot be combined with linear models",
      "It is only used in unsupervised learning"
    ],
    "correct": "It often produces sparse models with many weights exactly zero",
    "explanation": "L1 regularization can push some weights exactly to zero, effectively performing feature selection.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which metric is MOST appropriate when you care equally about false positives and false negatives in binary classification?",
    "options": [
      "Precision",
      "Recall",
      "Accuracy",
      "Training loss"
    ],
    "correct": "Accuracy",
    "explanation": "If errors are equally costly and classes are reasonably balanced, accuracy is a reasonable overall metric.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Precision in binary classification measures:",
    "options": [
      "The proportion of positive predictions that are correct",
      "The proportion of positive samples detected",
      "The overall fraction of correct predictions",
      "The number of true negatives"
    ],
    "correct": "The proportion of positive predictions that are correct",
    "explanation": "Precision = TP / (TP + FP); it answers: \"Of what we predicted as positive, how many were actually positive?\"",
    "topic": "Supervised Learning"
  },
  {
    "question": "Recall in binary classification measures:",
    "options": [
      "The proportion of positive predictions that are correct",
      "The proportion of actual positives that are correctly detected",
      "The fraction of negative samples detected",
      "The number of false negatives"
    ],
    "correct": "The proportion of actual positives that are correctly detected",
    "explanation": "Recall = TP / (TP + FN); it answers: \"Of all true positives, how many did we find?\"",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which metric is often used when missing a positive case is much worse than raising a false alarm?",
    "options": [
      "Recall",
      "Precision",
      "RMSE",
      "R-squared"
    ],
    "correct": "Recall",
    "explanation": "High recall ensures most actual positives are detected, important when false negatives are costly.",
    "topic": "Supervised Learning"
  },
  {
    "question": "The F1-score is the harmonic mean of:",
    "options": [
      "Accuracy and recall",
      "Precision and recall",
      "Precision and accuracy",
      "Loss and accuracy"
    ],
    "correct": "Precision and recall",
    "explanation": "F1 combines precision and recall, giving a balanced measure when both are important.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which situation suggests that precision is more important than recall?",
    "options": [
      "Detecting all cancer cases in medical screening",
      "Filtering spam emails where a few spam messages in the inbox are acceptable",
      "Detecting all fraudulent transactions regardless of false alarms",
      "Detecting rare machine failures where missing one is catastrophic"
    ],
    "correct": "Filtering spam emails where a few spam messages in the inbox are acceptable",
    "explanation": "For spam filters, marking legitimate mail as spam (false positives) is worse, so you favor high precision.",
    "topic": "AI Applications"
  },
  {
    "question": "In a confusion matrix, which cell corresponds to false positives (FP)?",
    "options": [
      "Predicted negative, actual negative",
      "Predicted negative, actual positive",
      "Predicted positive, actual positive",
      "Predicted positive, actual negative"
    ],
    "correct": "Predicted positive, actual negative",
    "explanation": "A false positive is when the model predicts positive but the true label is negative.",
    "topic": "Supervised Learning"
  },
  {
    "question": "The ROC curve plots:",
    "options": [
      "Precision vs recall",
      "True positive rate vs false positive rate",
      "Accuracy vs loss",
      "True positives vs true negatives"
    ],
    "correct": "True positive rate vs false positive rate",
    "explanation": "ROC curves show trade-offs between TPR (sensitivity) and FPR at different thresholds.",
    "topic": "Supervised Learning"
  },
  {
    "question": "AUC (Area Under the ROC Curve) close to 0.5 suggests that the model is:",
    "options": [
      "Performing perfectly",
      "Performing worse than random guessing",
      "Performing similarly to random guessing",
      "Overfitting the training data"
    ],
    "correct": "Performing similarly to random guessing",
    "explanation": "An AUC of 0.5 means the classifier has no discriminative power, like random guessing.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which of the following is an example of a parametric model?",
    "options": [
      "k-nearest neighbors",
      "Linear regression with fixed number of features",
      "Decision tree with unlimited depth",
      "k-means with dynamic number of clusters"
    ],
    "correct": "Linear regression with fixed number of features",
    "explanation": "Parametric models have a fixed number of parameters determined by the feature set, independent of data size.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which of these is a non-parametric algorithm?",
    "options": [
      "Linear regression",
      "Logistic regression",
      "k-nearest neighbors",
      "Lasso regression"
    ],
    "correct": "k-nearest neighbors",
    "explanation": "kNN stores the data and bases predictions on neighboring points; complexity grows with data size.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "How does k-nearest neighbors classify a new point?",
    "options": [
      "By fitting a global line through the data",
      "By selecting the majority class among the k closest training examples",
      "By computing the average label of all examples",
      "By randomly picking a label"
    ],
    "correct": "By selecting the majority class among the k closest training examples",
    "explanation": "kNN uses local neighbors to make predictions; the majority label among them is chosen.",
    "topic": "Supervised Learning"
  },
  {
    "question": "What is a typical drawback of k-nearest neighbors?",
    "options": [
      "It cannot classify nonlinear patterns",
      "It requires no distance metric",
      "It can be slow at prediction time on large datasets",
      "It does not use any training data"
    ],
    "correct": "It can be slow at prediction time on large datasets",
    "explanation": "kNN must compare the query point to many training examples, which is expensive at inference time.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which of the following is a typical hyperparameter in k-nearest neighbors?",
    "options": [
      "Learning rate",
      "Number of epochs",
      "Number of neighbors k",
      "Batch size"
    ],
    "correct": "Number of neighbors k",
    "explanation": "k determines how many neighbors are used to make the prediction.",
    "topic": "Supervised Learning"
  },
  {
    "question": "In a decision tree, which criterion is commonly used to select the best split for classification?",
    "options": [
      "Mean squared error",
      "Gini impurity or entropy",
      "Cosine similarity",
      "Euclidean distance"
    ],
    "correct": "Gini impurity or entropy",
    "explanation": "Decision trees often use Gini or entropy to measure the purity of splits for classification tasks.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Random forests reduce overfitting compared to a single decision tree by:",
    "options": [
      "Using fewer features",
      "Averaging predictions over many diverse trees",
      "Removing randomness from training",
      "Using only one deep tree"
    ],
    "correct": "Averaging predictions over many diverse trees",
    "explanation": "Random forests create an ensemble of trees trained on different subsets of data and features, then average their predictions.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which statement about gradient boosting is correct?",
    "options": [
      "It trains all trees completely independently",
      "It trains trees sequentially, each correcting the errors of the previous",
      "It does not use gradients",
      "It is the same as k-means clustering"
    ],
    "correct": "It trains trees sequentially, each correcting the errors of the previous",
    "explanation": "Gradient boosting builds an ensemble iteratively, focusing on residual errors from previous models.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which of the following is a typical benefit of using gradient boosted trees (e.g., XGBoost, LightGBM)?",
    "options": [
      "They require no hyperparameter tuning",
      "They often achieve strong performance on tabular data",
      "They only work with image inputs",
      "They never overfit"
    ],
    "correct": "They often achieve strong performance on tabular data",
    "explanation": "Gradient boosted trees are strong baselines for many structured/tabular data problems.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which method is commonly used to deal with missing numerical values?",
    "options": [
      "Deleting all columns",
      "Imputing with the mean or median",
      "Changing all values to zero",
      "Randomly generating new labels"
    ],
    "correct": "Imputing with the mean or median",
    "explanation": "Simple imputation methods fill missing values with summary statistics like mean or median.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which encoding technique is commonly used for categorical variables with no natural order?",
    "options": [
      "One-hot encoding",
      "Mean normalization",
      "Standardization",
      "Min-max scaling"
    ],
    "correct": "One-hot encoding",
    "explanation": "One-hot encoding represents each category with a binary vector, suitable for unordered categories.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which situation could lead to target leakage?",
    "options": [
      "Using features that are highly correlated",
      "Using features that are derived from the label itself",
      "Using multiple input features",
      "Using a validation set"
    ],
    "correct": "Using features that are derived from the label itself",
    "explanation": "If features contain direct information about the target that would not be available at prediction time, leakage occurs.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Why is it important to shuffle data before splitting into train and test sets?",
    "options": [
      "To reduce file size",
      "To ensure no correlation between features",
      "To avoid temporal or ordering patterns that would bias the split",
      "To make the labels easier to predict"
    ],
    "correct": "To avoid temporal or ordering patterns that would bias the split",
    "explanation": "If data is ordered (e.g., by time), without shuffling you may end up with non-representative train/test splits.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which validation approach is especially useful when data is limited?",
    "options": [
      "Using no validation set",
      "K-fold cross-validation",
      "Using only a test set",
      "Randomly changing labels"
    ],
    "correct": "K-fold cross-validation",
    "explanation": "Cross-validation maximizes data usage by rotating which folds are used for training and validation.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "What is early stopping in model training?",
    "options": [
      "Stopping training after the first epoch",
      "Stopping training when validation performance stops improving",
      "Stopping training when training loss reaches zero",
      "Stopping training when the model size is too large"
    ],
    "correct": "Stopping training when validation performance stops improving",
    "explanation": "Early stopping is a regularization technique that prevents overfitting by halting training based on validation metrics.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which of the following is an example of data augmentation in computer vision?",
    "options": [
      "Adding more labels to the dataset",
      "Randomly rotating and flipping input images",
      "Removing noisy images",
      "Reducing the image resolution"
    ],
    "correct": "Randomly rotating and flipping input images",
    "explanation": "Augmentation creates modified versions of existing images to enlarge the dataset and improve generalization.",
    "topic": "Deep Learning"
  },
  {
    "question": "Why is batch normalization often used in deep neural networks?",
    "options": [
      "To remove all non-linearities",
      "To normalize activations and stabilize training",
      "To reduce dataset size",
      "To convert labels into probabilities"
    ],
    "correct": "To normalize activations and stabilize training",
    "explanation": "Batch normalization helps keep intermediate activations in a stable range, speeding up convergence.",
    "topic": "Deep Learning"
  },
  {
    "question": "In NLP, a word embedding is:",
    "options": [
      "A numeric representation of words in a continuous vector space",
      "A one-hot encoding of characters",
      "A list of all words in a document",
      "A rule-based translation table"
    ],
    "correct": "A numeric representation of words in a continuous vector space",
    "explanation": "Embeddings map words to dense vectors that capture semantic similarity.",
    "topic": "AI Applications"
  },
  {
    "question": "Which advantage do transformer-based models have over traditional RNNs for NLP tasks?",
    "options": [
      "They cannot use attention mechanisms",
      "They process sequences strictly left-to-right",
      "They handle long-range dependencies more effectively using self-attention",
      "They use fewer parameters than any RNN"
    ],
    "correct": "They handle long-range dependencies more effectively using self-attention",
    "explanation": "Transformers rely on self-attention, which allows them to capture relationships between words regardless of distance.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which of the following is a typical risk when deploying an AI system that interacts directly with end users?",
    "options": [
      "The model will always achieve 100% accuracy",
      "Users may rely too heavily on model outputs without critical thinking",
      "The system will never produce biased outputs",
      "The system cannot learn from new data"
    ],
    "correct": "Users may rely too heavily on model outputs without critical thinking",
    "explanation": "Over-trust in AI systems can lead users to accept incorrect or biased predictions.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "What does 'fairness through unawareness' mean in AI?",
    "options": [
      "Ignoring all demographic features guarantees fairness",
      "Not using sensitive attributes in training or prediction",
      "Removing all labels from the dataset",
      "Not monitoring the model after deployment"
    ],
    "correct": "Not using sensitive attributes in training or prediction",
    "explanation": "Fairness through unawareness omits protected attributes, though this alone does not guarantee fairness.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Why might simply removing a protected attribute (e.g., gender) from the data be insufficient to avoid bias?",
    "options": [
      "Because models cannot handle missing attributes",
      "Because other features may act as proxies for the protected attribute",
      "Because we must always include all attributes",
      "Because bias only exists in the labels"
    ],
    "correct": "Because other features may act as proxies for the protected attribute",
    "explanation": "Even without explicit sensitive features, correlated features can leak similar information, sustaining bias.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which of the following BEST describes 'model interpretability'?",
    "options": [
      "How fast a model trains",
      "How easy it is for humans to understand how the model makes decisions",
      "How small the model file is",
      "How many GPUs are required for training"
    ],
    "correct": "How easy it is for humans to understand how the model makes decisions",
    "explanation": "Interpretability focuses on making model logic understandable to humans.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which of the following models is usually considered easier to interpret?",
    "options": [
      "A single small decision tree",
      "A very deep neural network with millions of parameters",
      "A large ensemble of gradient boosted trees",
      "A transformer-based language model"
    ],
    "correct": "A single small decision tree",
    "explanation": "Small decision trees can be visualized and followed step-by-step, making them more interpretable.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "What is the main purpose of tools like LIME or SHAP?",
    "options": [
      "To optimize GPU usage",
      "To automatically label datasets",
      "To provide local explanations for individual model predictions",
      "To compress neural networks"
    ],
    "correct": "To provide local explanations for individual model predictions",
    "explanation": "LIME and SHAP are post-hoc explanation methods that help interpret black-box models.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which statement about data governance in AI is correct?",
    "options": [
      "It focuses only on model hyperparameters",
      "It defines how data is collected, stored, accessed, and used responsibly",
      "It only applies to public datasets",
      "It is only relevant for deep learning models"
    ],
    "correct": "It defines how data is collected, stored, accessed, and used responsibly",
    "explanation": "Data governance sets rules and processes for ethical and compliant data use.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "GDPR (General Data Protection Regulation) in the EU is mainly concerned with:",
    "options": [
      "Optimizing deep learning performance",
      "Regulating cryptocurrency",
      "Protecting personal data and privacy of individuals",
      "Deciding which AI models are allowed"
    ],
    "correct": "Protecting personal data and privacy of individuals",
    "explanation": "GDPR sets rules on how organizations can collect and process personal data.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which of the following describes 'data minimization'?",
    "options": [
      "Collecting as much data as possible",
      "Collecting only the data necessary for a specific purpose",
      "Deleting all existing datasets",
      "Using only synthetic data"
    ],
    "correct": "Collecting only the data necessary for a specific purpose",
    "explanation": "Data minimization is a privacy principle that limits data collection to what is strictly needed.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which threat is MOST related to AI security?",
    "options": [
      "Slow user interface",
      "Unauthorized weight updates to the model",
      "High model accuracy",
      "Small training set"
    ],
    "correct": "Unauthorized weight updates to the model",
    "explanation": "Tampering with model parameters can change behavior and undermine trust and safety.",
    "topic": "AI Security"
  },
  {
    "question": "Which example describes a 'poisoning attack' on a training dataset?",
    "options": [
      "Adding adversarial noise to test images",
      "Injecting carefully crafted malicious data into the training set to manipulate the model",
      "Removing all labels from the dataset",
      "Compressing images to save storage"
    ],
    "correct": "Injecting carefully crafted malicious data into the training set to manipulate the model",
    "explanation": "In poisoning attacks, adversaries corrupt training data to influence model behavior.",
    "topic": "AI Security"
  },
  {
    "question": "Which property does differential privacy aim to provide?",
    "options": [
      "Perfect accuracy",
      "Unlimited data sharing",
      "Formal guarantees that individual records have limited influence on model outputs",
      "Faster training time"
    ],
    "correct": "Formal guarantees that individual records have limited influence on model outputs",
    "explanation": "Differential privacy ensures that removing or adding a single data point does not significantly change model outputs.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which of the following is a benefit of using pre-trained models in computer vision?",
    "options": [
      "They always match the exact target domain",
      "They allow you to start from useful visual features and train with less labeled data",
      "They remove the need for any training",
      "They guarantee zero bias"
    ],
    "correct": "They allow you to start from useful visual features and train with less labeled data",
    "explanation": "Pre-trained models capture generic features; fine-tuning them can save time and data.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which scenario is well suited for transfer learning?",
    "options": [
      "You have millions of labeled images for your specific task",
      "You have only a small labeled dataset similar to a large public dataset",
      "You have no data at all",
      "You need an unsupervised clustering solution"
    ],
    "correct": "You have only a small labeled dataset similar to a large public dataset",
    "explanation": "Transfer learning is particularly useful when labeled data is scarce but related pre-trained models exist.",
    "topic": "Deep Learning"
  },
  {
    "question": "What is model deployment?",
    "options": [
      "Saving the model to disk only",
      "Using the trained model in a production environment to serve predictions",
      "Deleting the training data",
      "Visualizing the training loss"
    ],
    "correct": "Using the trained model in a production environment to serve predictions",
    "explanation": "Deployment is when the model is integrated into applications or services for real users.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which of the following is important for model monitoring after deployment?",
    "options": [
      "GPU fan speed",
      "User keyboard layout",
      "Tracking input distributions and model performance over time",
      "The color of the web interface"
    ],
    "correct": "Tracking input distributions and model performance over time",
    "explanation": "Monitoring detects data drift and performance degradation in production.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which concept refers to automatically retraining and re-deploying models as new data becomes available?",
    "options": [
      "Static modeling",
      "Continuous integration",
      "Continuous training and deployment (MLOps)",
      "Batch normalization"
    ],
    "correct": "Continuous training and deployment (MLOps)",
    "explanation": "MLOps practices support ongoing retraining, evaluation, and redeployment of models.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which objective is MOST important when designing an AI system for a safety-critical application (e.g., autonomous driving)?",
    "options": [
      "Maximizing user engagement",
      "Minimizing training time",
      "Ensuring reliability, robustness, and fail-safe behavior",
      "Using the newest model architecture"
    ],
    "correct": "Ensuring reliability, robustness, and fail-safe behavior",
    "explanation": "Safety-critical systems must prioritize reliability and safety over novelty or training speed.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which statement best describes supervised vs unsupervised learning?",
    "options": [
      "Supervised uses labeled data; unsupervised uses unlabeled data",
      "Supervised uses images; unsupervised uses text",
      "Supervised is always better than unsupervised",
      "Unsupervised learning does not use data"
    ],
    "correct": "Supervised uses labeled data; unsupervised uses unlabeled data",
    "explanation": "The main difference is the presence or absence of labels for training.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which learning paradigm is MOST appropriate for grouping news articles into thematic clusters without predefined labels?",
    "options": [
      "Supervised learning",
      "Unsupervised learning",
      "Reinforcement learning",
      "Semi-supervised learning"
    ],
    "correct": "Unsupervised learning",
    "explanation": "Clustering without labels is an unsupervised learning task.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Which type of model would be most appropriate for predicting tomorrow's stock price movement (up or down)?",
    "options": [
      "Binary classification model",
      "k-means clustering model",
      "Unsupervised anomaly detector",
      "Topic model"
    ],
    "correct": "Binary classification model",
    "explanation": "Predicting up vs down is a binary classification task.",
    "topic": "AI Applications"
  },
  {
    "question": "If a regression model consistently predicts values that are too low, which situation does this indicate?",
    "options": [
      "Low variance",
      "High variance",
      "High bias",
      "Low bias"
    ],
    "correct": "High bias",
    "explanation": "Systematic error in one direction suggests bias in the model.",
    "topic": "Regression Models"
  },
  {
    "question": "Which metric is commonly used to evaluate regression models?",
    "options": [
      "Precision",
      "Recall",
      "Mean absolute error (MAE)",
      "Accuracy"
    ],
    "correct": "Mean absolute error (MAE)",
    "explanation": "MAE measures the average absolute difference between predictions and true values.",
    "topic": "Regression Models"
  },
  {
    "question": "Which statement about RMSE (Root Mean Squared Error) is correct?",
    "options": [
      "It penalizes large errors more than MAE",
      "It is always equal to MAE",
      "It is only used for classification",
      "It ignores outliers"
    ],
    "correct": "It penalizes large errors more than MAE",
    "explanation": "Because errors are squared before averaging, RMSE is more sensitive to large errors.",
    "topic": "Regression Models"
  },
  {
    "question": "Which type of problem would benefit from multi-label classification?",
    "options": [
      "Predicting a single house price",
      "Assigning multiple genres (e.g., comedy and romance) to a movie",
      "Clustering customers by spending",
      "Detecting anomalies in sensor data"
    ],
    "correct": "Assigning multiple genres (e.g., comedy and romance) to a movie",
    "explanation": "Multi-label classification allows assigning several labels to one instance.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which of the following is an example of time series data?",
    "options": [
      "A set of random images",
      "Daily temperature measurements for one city over a year",
      "A list of unique IDs",
      "An unordered set of sentences"
    ],
    "correct": "Daily temperature measurements for one city over a year",
    "explanation": "Time series data is indexed by time and order matters.",
    "topic": "AI Applications"
  },
  {
    "question": "Which challenge is specific to time series forecasting compared to standard regression?",
    "options": [
      "The labels are categorical",
      "The observations are independent and identically distributed",
      "The observations are ordered and often autocorrelated",
      "No training data is available"
    ],
    "correct": "The observations are ordered and often autocorrelated",
    "explanation": "Time series models must account for temporal dependencies and ordering.",
    "topic": "AI Applications"
  },
  {
    "question": "Which model type is often used for univariate time series forecasting?",
    "options": [
      "ARIMA models",
      "k-means clustering",
      "Naive Bayes classifier",
      "Topic models"
    ],
    "correct": "ARIMA models",
    "explanation": "ARIMA is a classical method for time series forecasting using autoregressive and moving average components.",
    "topic": "AI Applications"
  },
  {
    "question": "In reinforcement learning, a policy defines:",
    "options": [
      "The reward function",
      "The value of each state",
      "How the agent selects actions based on states",
      "The environment transition probabilities"
    ],
    "correct": "How the agent selects actions based on states",
    "explanation": "A policy maps states to actions, guiding the agent's behavior.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "Which of the following is an example of a reward function in a game-playing RL agent?",
    "options": [
      "The architecture of the neural network",
      "The score received at the end of the game",
      "The number of training episodes",
      "The learning rate schedule"
    ],
    "correct": "The score received at the end of the game",
    "explanation": "Reward functions map states and actions (or episodes) to scalar feedback values like game scores.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "What is the discount factor (gamma) in reinforcement learning used for?",
    "options": [
      "Controlling learning rate",
      "Balancing immediate and future rewards",
      "Selecting the exploration strategy",
      "Normalizing input features"
    ],
    "correct": "Balancing immediate and future rewards",
    "explanation": "Gamma determines how much future rewards influence current decisions.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "Which exploration strategy in RL involves choosing a random action with probability ε and the best-known action otherwise?",
    "options": [
      "Softmax policy",
      "ε-greedy policy",
      "Greedy policy with no exploration",
      "Random walk"
    ],
    "correct": "ε-greedy policy",
    "explanation": "ε-greedy balances exploration and exploitation via a small probability of random actions.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "Which situation is MOST likely to cause concept drift?",
    "options": [
      "Temperature sensor readings in a lab with constant conditions",
      "Customer preferences changing over time in an online shop",
      "Static physical constants like the speed of light",
      "Historical books in a library"
    ],
    "correct": "Customer preferences changing over time in an online shop",
    "explanation": "When the relationship between inputs and outputs changes over time, concept drift occurs.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which statement about offline vs online learning is correct?",
    "options": [
      "Offline learning updates the model continuously with each new example",
      "Online learning trains once on a fixed batch of data",
      "Online learning updates the model incrementally as new data arrives",
      "They are identical concepts"
    ],
    "correct": "Online learning updates the model incrementally as new data arrives",
    "explanation": "Online learning adapts to new data in a streaming fashion; offline learning uses static datasets.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which problem arises if you evaluate many models on the same test set and pick the best one?",
    "options": [
      "Data leakage in training",
      "Overfitting to the test set",
      "Underfitting all models",
      "No problem; this is recommended"
    ],
    "correct": "Overfitting to the test set",
    "explanation": "Repeatedly choosing the best model on the same test set can make results overly optimistic.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which approach helps reduce the risk of overfitting to the test set?",
    "options": [
      "Using a separate validation set and keeping the test set untouched until final evaluation",
      "Using only the test set for training",
      "Never using a validation set",
      "Randomly changing the labels in the test set"
    ],
    "correct": "Using a separate validation set and keeping the test set untouched until final evaluation",
    "explanation": "The validation set is used for model selection; the test set is reserved for final assessment.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "In responsible AI, which group should ideally be involved when defining requirements and evaluating systems?",
    "options": [
      "Only the data scientists",
      "Only software engineers",
      "Stakeholders including domain experts, end-users, and affected groups",
      "Only upper management"
    ],
    "correct": "Stakeholders including domain experts, end-users, and affected groups",
    "explanation": "Engaging diverse stakeholders helps surface requirements, risks, and fairness concerns.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which is a potential environmental concern related to training large AI models?",
    "options": [
      "They always reduce energy consumption",
      "They require no electricity",
      "They can consume significant computational resources and energy",
      "They cannot be trained on GPUs"
    ],
    "correct": "They can consume significant computational resources and energy",
    "explanation": "Large models often need substantial compute, leading to notable energy usage and carbon footprint.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which statement about synthetic data is correct?",
    "options": [
      "It is always a perfect replacement for real data",
      "It can help protect privacy but may not capture all real-world nuances",
      "It cannot be used for training models",
      "It is always less diverse than real data"
    ],
    "correct": "It can help protect privacy but may not capture all real-world nuances",
    "explanation": "Synthetic data provides privacy benefits, but its quality and representativeness must be validated.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which scenario illustrates a 'black-box' model?",
    "options": [
      "A small rule-based system with explicit rules",
      "A shallow linear regression with two features",
      "A deep neural network with millions of parameters and no simple explanation",
      "A simple decision tree with three levels"
    ],
    "correct": "A deep neural network with millions of parameters and no simple explanation",
    "explanation": "Complex deep nets are often considered black boxes due to their lack of transparent decision rules.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "What is a key challenge with black-box AI models in regulated domains (e.g., finance)?",
    "options": [
      "They are always too slow",
      "They do not support classification tasks",
      "They may violate requirements for transparency and explainability",
      "They cannot handle numerical data"
    ],
    "correct": "They may violate requirements for transparency and explainability",
    "explanation": "Regulators may require understandable decision-making, which conflicts with opaque models.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which of the following AI applications is MOST directly related to anomaly detection?",
    "options": [
      "Topic modeling of news articles",
      "Real-time fraud detection in credit card transactions",
      "Machine translation between languages",
      "Image segmentation in medical scans"
    ],
    "correct": "Real-time fraud detection in credit card transactions",
    "explanation": "Fraud often appears as unusual patterns departing from normal behavior, a classic anomaly detection task.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Why are autoencoders often used for anomaly detection?",
    "options": [
      "They memorize every training example exactly",
      "They learn to reconstruct normal data; large reconstruction error may indicate anomalies",
      "They always produce perfect classifications",
      "They require no training data"
    ],
    "correct": "They learn to reconstruct normal data; large reconstruction error may indicate anomalies",
    "explanation": "Autoencoders trained on normal data struggle to reconstruct unusual patterns, signaling anomalies.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which statement about clustering evaluation without labels is correct?",
    "options": [
      "It is impossible to evaluate clustering without labels",
      "You can use internal metrics like silhouette score to measure cluster separation",
      "You must always create manual labels first",
      "Only visual inspection is allowed"
    ],
    "correct": "You can use internal metrics like silhouette score to measure cluster separation",
    "explanation": "Internal metrics evaluate clustering based on cohesion and separation without external labels.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Which challenge often arises when choosing the number of clusters k in k-means?",
    "options": [
      "k must always equal the number of features",
      "There is no single objective way to pick k; it often requires experimentation and domain knowledge",
      "k must always be 2",
      "k is automatically determined by the algorithm"
    ],
    "correct": "There is no single objective way to pick k; it often requires experimentation and domain knowledge",
    "explanation": "Choosing k is problem-dependent and typically involves methods like the elbow method plus domain input.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Which type of AI system adjusts its behavior based on feedback but does NOT explicitly learn from data?",
    "options": [
      "Rule-based expert system with manually updated rules",
      "Deep neural network",
      "Linear regression model",
      "Random forest classifier"
    ],
    "correct": "Rule-based expert system with manually updated rules",
    "explanation": "Expert systems rely on human-updated rules rather than data-driven learning.",
    "topic": "AI Fundamentals"
  },
  {
    "question": "Which is a main limitation of rule-based systems compared to modern ML systems?",
    "options": [
      "They cannot be implemented in software",
      "They become hard to maintain as the number of rules grows",
      "They require large labeled datasets",
      "They always outperform neural networks"
    ],
    "correct": "They become hard to maintain as the number of rules grows",
    "explanation": "Rule sets can become inconsistent and unmanageable as complexity increases.",
    "topic": "AI Fundamentals"
  },
  {
    "question": "Which property makes AI systems different from traditional software in many applications?",
    "options": [
      "AI systems never fail",
      "AI systems can learn patterns from data instead of being fully hand-coded",
      "AI systems require no testing",
      "AI systems can run without hardware"
    ],
    "correct": "AI systems can learn patterns from data instead of being fully hand-coded",
    "explanation": "ML-based AI learns from data, while traditional software encodes explicit rules.",
    "topic": "AI Fundamentals"
  },
  {
    "question": "Which term describes errors in a dataset where labels are systematically incorrect for a specific group?",
    "options": [
      "Random noise",
      "Sampling error",
      "Label bias",
      "Overfitting"
    ],
    "correct": "Label bias",
    "explanation": "Label bias occurs when certain groups are labeled incorrectly more often, embedding historical unfairness.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which mitigation strategy can improve robustness against label bias?",
    "options": [
      "Ignoring evaluation metrics",
      "Collecting more diverse and carefully checked labeled data",
      "Removing the training data",
      "Using a more complex model regardless of data quality"
    ],
    "correct": "Collecting more diverse and carefully checked labeled data",
    "explanation": "Better, more representative, and audited labels can reduce biased patterns the model might learn.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which statement best describes artificial intelligence (AI)?",
    "options": [
      "Any software that runs on a computer",
      "Systems that perform tasks requiring human-like intelligence",
      "Only robots that move and act in the physical world",
      "Any program that uses a database"
    ],
    "correct": "Systems that perform tasks requiring human-like intelligence",
    "explanation": "AI focuses on building systems that can perform tasks such as perception, reasoning, and learning that typically require human intelligence.",
    "topic": "AI Fundamentals"
  },
  {
    "question": "What is the main difference between narrow AI and general AI?",
    "options": [
      "Narrow AI works only with images, general AI only with text",
      "Narrow AI is rule-based, general AI is not",
      "Narrow AI is built for specific tasks, general AI can handle a wide range of tasks",
      "Narrow AI requires big data, general AI does not"
    ],
    "correct": "Narrow AI is built for specific tasks, general AI can handle a wide range of tasks",
    "explanation": "Narrow AI is specialized for a single or limited set of tasks, while general AI would exhibit flexible, human-level intelligence across many domains.",
    "topic": "AI Fundamentals"
  },
  {
    "question": "Which of the following is an example of narrow AI?",
    "options": [
      "A robot that can do any job a human can do",
      "A chess-playing program that beats world champions",
      "A system that understands and reasons about everything",
      "A computer that designs new AI systems without data"
    ],
    "correct": "A chess-playing program that beats world champions",
    "explanation": "Game-playing systems like Deep Blue or AlphaZero are classic examples of narrow AI focused on a single task.",
    "topic": "AI Applications"
  },
  {
    "question": "Which term describes computers performing tasks that normally require human intelligence, like learning or reasoning?",
    "options": [
      "Machine coding",
      "Robotics process automation",
      "Artificial intelligence",
      "Cloud computing"
    ],
    "correct": "Artificial intelligence",
    "explanation": "Artificial intelligence is the field concerned with automating tasks that usually require human intelligence.",
    "topic": "AI Fundamentals"
  },
  {
    "question": "What is a key characteristic of supervised learning?",
    "options": [
      "It does not use any data",
      "It uses labeled examples of inputs and outputs",
      "It never updates its model parameters",
      "It only works for clustering tasks"
    ],
    "correct": "It uses labeled examples of inputs and outputs",
    "explanation": "Supervised learning requires labeled data, where the correct output is known for each input.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which of the following tasks is most suitable for supervised learning?",
    "options": [
      "Discovering groups of similar customers",
      "Detecting fraudulent credit card transactions as 'fraud' or 'not fraud'",
      "Generating synthetic data",
      "Compressing images without losing information"
    ],
    "correct": "Detecting fraudulent credit card transactions as 'fraud' or 'not fraud'",
    "explanation": "Fraud detection is a classification problem with labeled examples, making it a good fit for supervised learning.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which learning paradigm is primarily concerned with discovering structure in unlabeled data?",
    "options": [
      "Supervised learning",
      "Unsupervised learning",
      "Reinforcement learning",
      "Semi-supervised learning"
    ],
    "correct": "Unsupervised learning",
    "explanation": "Unsupervised learning tries to find patterns or groupings in data where labels are not provided.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Clustering algorithms are typically used to:",
    "options": [
      "Predict continuous values like house prices",
      "Assign predefined labels to examples",
      "Group similar examples without predefined labels",
      "Generate new synthetic images"
    ],
    "correct": "Group similar examples without predefined labels",
    "explanation": "Clustering is an unsupervised learning technique that groups similar data points without using labels.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Reinforcement learning is best described as:",
    "options": [
      "Learning from labeled examples of correct behavior",
      "Learning by exploring an environment and receiving rewards or penalties",
      "Learning by copying the model weights of another agent",
      "Learning from static rules defined by experts"
    ],
    "correct": "Learning by exploring an environment and receiving rewards or penalties",
    "explanation": "Reinforcement learning agents learn by interacting with an environment and optimizing cumulative reward.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "Which scenario is a good example of reinforcement learning?",
    "options": [
      "Grouping products by similarity based on purchase data",
      "Training an agent to play a video game by trial and error",
      "Classifying emails as spam or not spam",
      "Predicting tomorrow's temperature"
    ],
    "correct": "Training an agent to play a video game by trial and error",
    "explanation": "Game-playing agents that learn by trial and error with rewards fit the reinforcement learning paradigm.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "What type of machine learning is used when a model predicts housing prices based on past sales data?",
    "options": [
      "Clustering",
      "Classification",
      "Regression",
      "Dimensionality reduction"
    ],
    "correct": "Regression",
    "explanation": "Predicting a continuous value such as price is a regression task.",
    "topic": "Regression Models"
  },
  {
    "question": "Which of the following is a typical output of a classification model?",
    "options": [
      "Predicted house price in euros",
      "Cluster index of a data point",
      "Probability that an email is spam",
      "Reconstructed compressed image"
    ],
    "correct": "Probability that an email is spam",
    "explanation": "Classification models predict class labels or probabilities for discrete categories like spam or not spam.",
    "topic": "Supervised Learning"
  },
  {
    "question": "In a spam filter, the labels 'spam' and 'not spam' are examples of:",
    "options": [
      "Continuous variables",
      "Classes",
      "Hyperparameters",
      "Loss functions"
    ],
    "correct": "Classes",
    "explanation": "In supervised classification, each possible category is called a class.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which of the following is most likely a regression problem?",
    "options": [
      "Predicting which product a user will click",
      "Estimating the number of sales next week",
      "Classifying images of animals into species",
      "Detecting fraudulent transactions"
    ],
    "correct": "Estimating the number of sales next week",
    "explanation": "Estimating a numeric quantity, like sales count, is a regression task.",
    "topic": "Regression Models"
  },
  {
    "question": "What is the main goal of a classification algorithm?",
    "options": [
      "To group similar items without labels",
      "To predict continuous numerical targets",
      "To find the best sequence of actions in an environment",
      "To assign an input to one of several predefined categories"
    ],
    "correct": "To assign an input to one of several predefined categories",
    "explanation": "Classification maps inputs to discrete labels such as 'cat' or 'dog'.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which statement about outliers is generally true?",
    "options": [
      "Outliers are always removed from the dataset",
      "Outliers never influence machine learning models",
      "How to treat outliers depends on the problem and model",
      "Outliers only exist in categorical data"
    ],
    "correct": "How to treat outliers depends on the problem and model",
    "explanation": "Sometimes outliers represent important rare events; sometimes they are noise. Treatment depends on context.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "What is feature engineering?",
    "options": [
      "The process of randomly shuffling data",
      "The process of transforming raw data into useful input features",
      "The process of labeling data with ground truth",
      "The process of training the final model"
    ],
    "correct": "The process of transforming raw data into useful input features",
    "explanation": "Feature engineering creates or transforms variables to make patterns easier for models to learn.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which of the following is an example of feature engineering?",
    "options": [
      "Randomly dropping half of the dataset",
      "Combining 'day', 'month', and 'year' columns into a single 'date' feature",
      "Shuffling the order of the training examples",
      "Splitting the dataset into train and test sets"
    ],
    "correct": "Combining 'day', 'month', and 'year' columns into a single 'date' feature",
    "explanation": "Creating new features from existing columns is a classic feature engineering step.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "When you do a typical 70%/30% train-test split, what is the main purpose of the test set?",
    "options": [
      "To train the model faster",
      "To tune hyperparameters during training",
      "To evaluate how well the model generalizes to unseen data",
      "To generate more training examples"
    ],
    "correct": "To evaluate how well the model generalizes to unseen data",
    "explanation": "The test set is held out from training and used to estimate performance on new, unseen data.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which statement best describes cross-validation?",
    "options": [
      "Using the same data for training and testing",
      "Repeatedly splitting the data into different train and validation sets to evaluate performance",
      "Training multiple different models on completely different datasets",
      "Randomly shuffling the labels to remove bias"
    ],
    "correct": "Repeatedly splitting the data into different train and validation sets to evaluate performance",
    "explanation": "Cross-validation helps estimate how a model will perform on unseen data by rotating which samples are used for training and validation.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Why is it important that the training and test data come from the same distribution?",
    "options": [
      "To make the model train faster",
      "So the model can memorize the test data",
      "So evaluation results reflect how the model will behave in production",
      "Because models cannot handle any distribution shift"
    ],
    "correct": "So evaluation results reflect how the model will behave in production",
    "explanation": "If training and test data are drawn from different distributions, test performance may not reflect real-world performance.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "A model trained only on adult cat images performs poorly on kitten images in production. What is the best way to address this?",
    "options": [
      "Reduce the number of training examples",
      "Add representative kitten images to the training data",
      "Increase the learning rate",
      "Remove all cat images from training"
    ],
    "correct": "Add representative kitten images to the training data",
    "explanation": "The production distribution includes kitten images, so training data should include similar examples.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "What does overfitting mean in the context of machine learning?",
    "options": [
      "The model has too few parameters to learn the pattern",
      "The model performs well on training data but poorly on new data",
      "The model uses too little training data",
      "The model converges too quickly"
    ],
    "correct": "The model performs well on training data but poorly on new data",
    "explanation": "Overfitting occurs when a model memorizes training data instead of learning general patterns.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which strategy is commonly used to reduce overfitting?",
    "options": [
      "Using a more complex model",
      "Collecting more training data",
      "Removing the validation set",
      "Increasing the number of training epochs indefinitely"
    ],
    "correct": "Collecting more training data",
    "explanation": "More diverse data helps models generalize better and reduces overfitting.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "The bias-variance tradeoff refers to:",
    "options": [
      "Balancing training and test set sizes",
      "Balancing the number of features and samples",
      "Balancing underfitting and overfitting in model complexity",
      "Balancing the number of labels and unlabeled samples"
    ],
    "correct": "Balancing underfitting and overfitting in model complexity",
    "explanation": "High bias can cause underfitting, while high variance can cause overfitting; choosing the right complexity balances these.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "What is the primary purpose of a loss function in supervised learning?",
    "options": [
      "To generate new training data",
      "To measure how far predictions are from true labels",
      "To split data into batches",
      "To normalize input features"
    ],
    "correct": "To measure how far predictions are from true labels",
    "explanation": "The loss function quantifies prediction error and guides the optimization process.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which of the following is a common loss function for regression problems?",
    "options": [
      "Cross-entropy loss",
      "Mean squared error",
      "Hinge loss",
      "F1-score"
    ],
    "correct": "Mean squared error",
    "explanation": "Mean squared error is widely used to measure the average squared difference between predictions and true values in regression.",
    "topic": "Regression Models"
  },
  {
    "question": "Which metric is most suitable for evaluating binary classification performance on an imbalanced dataset?",
    "options": [
      "Accuracy",
      "Mean squared error",
      "F1-score",
      "Mean absolute error"
    ],
    "correct": "F1-score",
    "explanation": "F1-score balances precision and recall, making it more informative than accuracy on imbalanced data.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which of the following best describes a confusion matrix?",
    "options": [
      "A matrix showing correlations between features",
      "A table summarizing correct and incorrect classifications",
      "A table storing model hyperparameters",
      "A matrix of distances between data points"
    ],
    "correct": "A table summarizing correct and incorrect classifications",
    "explanation": "A confusion matrix shows counts of true positives, false positives, true negatives, and false negatives.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Why is feature scaling (normalization or standardization) often important?",
    "options": [
      "To convert categorical data into numbers",
      "To reduce model interpretability",
      "To ensure features contribute roughly equally to distance-based or gradient-based algorithms",
      "To remove all correlations between features"
    ],
    "correct": "To ensure features contribute roughly equally to distance-based or gradient-based algorithms",
    "explanation": "If features are on very different scales, optimization and distance calculations can be dominated by large-scale features.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which of the following is an example of synthetic data generation?",
    "options": [
      "Removing rows with missing values",
      "Creating simulated customer transactions that resemble real ones",
      "Normalizing all features to have mean zero",
      "Labeling images with object categories"
    ],
    "correct": "Creating simulated customer transactions that resemble real ones",
    "explanation": "Synthetic data is artificially generated to mimic properties of real data.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Data anonymization is primarily used to:",
    "options": [
      "Improve model accuracy",
      "Speed up training",
      "Protect the privacy of individuals in a dataset",
      "Increase the number of features"
    ],
    "correct": "Protect the privacy of individuals in a dataset",
    "explanation": "Anonymization removes or masks identifying information to protect individuals' privacy.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "In machine learning projects, practitioners typically spend most of their time on:",
    "options": [
      "Designing model architectures",
      "Data collection, cleaning, and preprocessing",
      "Tuning learning rates",
      "Writing documentation"
    ],
    "correct": "Data collection, cleaning, and preprocessing",
    "explanation": "In practice, preparing high-quality data is often the most time-consuming part of a project.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "What is the main purpose of splitting data into training, validation, and test sets?",
    "options": [
      "To use each split for a different algorithm",
      "To hide part of the data from the model permanently",
      "To train, tune, and objectively evaluate the model respectively",
      "To increase the total number of samples"
    ],
    "correct": "To train, tune, and objectively evaluate the model respectively",
    "explanation": "Training data fits the model, validation data tunes hyperparameters, and test data measures final performance.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which of the following best describes a hyperparameter?",
    "options": [
      "A parameter learned by the model from data",
      "A parameter that controls the learning process and is set by the practitioner",
      "Any parameter in the loss function",
      "The bias term in a linear model"
    ],
    "correct": "A parameter that controls the learning process and is set by the practitioner",
    "explanation": "Hyperparameters like learning rate or tree depth are set before training and control how the model learns.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "In a decision tree, what is the purpose of splitting on features?",
    "options": [
      "To create new labels",
      "To partition the data into subsets that are more homogeneous with respect to the target variable",
      "To increase the number of features",
      "To normalize the data"
    ],
    "correct": "To partition the data into subsets that are more homogeneous with respect to the target variable",
    "explanation": "Decision trees split data so that each branch is more pure (similar labels) than before the split.",
    "topic": "Supervised Learning"
  },
  {
    "question": "What is one advantage of decision trees?",
    "options": [
      "They are always the most accurate model",
      "They are easy to interpret and visualize",
      "They never overfit the training data",
      "They require no features"
    ],
    "correct": "They are easy to interpret and visualize",
    "explanation": "Decision trees present decisions in a tree structure that humans can inspect and understand.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which of the following algorithms assumes that features are conditionally independent given the class label?",
    "options": [
      "k-means clustering",
      "Naive Bayes",
      "Linear regression",
      "k-nearest neighbors"
    ],
    "correct": "Naive Bayes",
    "explanation": "Naive Bayes relies on the simplifying assumption that features are independent given the class.",
    "topic": "Supervised Learning"
  },
  {
    "question": "What is a hyperplane in the context of support vector machines (SVMs)?",
    "options": [
      "A method for scaling data",
      "A decision boundary that separates classes",
      "A type of activation function",
      "A loss function used for regression"
    ],
    "correct": "A decision boundary that separates classes",
    "explanation": "SVMs use hyperplanes in feature space as decision boundaries between classes.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Why are support vector machines often effective for classification problems?",
    "options": [
      "They do not require any features",
      "They find a decision boundary with maximum margin between classes",
      "They always output probabilities directly",
      "They cannot handle nonlinear decision boundaries"
    ],
    "correct": "They find a decision boundary with maximum margin between classes",
    "explanation": "Maximizing the margin often improves generalization, making SVMs effective.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which type of regression is used when the output is binary (0 or 1)?",
    "options": [
      "Linear regression",
      "Polynomial regression",
      "Logistic regression",
      "k-means regression"
    ],
    "correct": "Logistic regression",
    "explanation": "Logistic regression models the probability of a binary outcome using a logistic (sigmoid) function.",
    "topic": "Regression Models"
  },
  {
    "question": "The sigmoid function outputs values in which range?",
    "options": [
      "-1 to 1",
      "0 to 1",
      "0 to 10",
      "0 to 100"
    ],
    "correct": "0 to 1",
    "explanation": "The sigmoid activation squashes real-valued inputs to the range between 0 and 1.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which of the following best describes a neural network?",
    "options": [
      "A set of hand-written rules",
      "A collection of interconnected nodes (neurons) that transform inputs through layers",
      "A single linear equation with one parameter",
      "A type of decision tree"
    ],
    "correct": "A collection of interconnected nodes (neurons) that transform inputs through layers",
    "explanation": "Neural networks are composed of layers of artificial neurons connected by weighted edges.",
    "topic": "Deep Learning"
  },
  {
    "question": "What is the role of an activation function in a neural network?",
    "options": [
      "To initialize weights",
      "To add non-linearity so the network can learn complex patterns",
      "To sort training examples",
      "To compute the loss function"
    ],
    "correct": "To add non-linearity so the network can learn complex patterns",
    "explanation": "Activation functions like ReLU or sigmoid allow networks to approximate complex, non-linear functions.",
    "topic": "Deep Learning"
  },
  {
    "question": "ReLU (Rectified Linear Unit) activation is defined as:",
    "options": [
      "1 / (1 + e^-x)",
      "max(0, x)",
      "x^2",
      "-x",
      "log(1 + e^x)"
    ],
    "correct": "max(0, x)",
    "explanation": "ReLU outputs zero for negative inputs and the input itself for non-negative inputs.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which neural network architecture is particularly well-suited for image recognition?",
    "options": [
      "Recurrent neural networks",
      "Convolutional neural networks",
      "Naive Bayes networks",
      "Bayesian belief networks"
    ],
    "correct": "Convolutional neural networks",
    "explanation": "CNNs use convolutional layers that exploit spatial structure in images.",
    "topic": "Deep Learning"
  },
  {
    "question": "What is a convolutional filter (kernel) used for in CNNs?",
    "options": [
      "To randomly initialize weights",
      "To compute global averages",
      "To detect local patterns like edges or textures",
      "To generate labels for images"
    ],
    "correct": "To detect local patterns like edges or textures",
    "explanation": "Convolutional filters slide over the image to detect local features.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which neural network architecture is typically used for sequence data such as text or time series?",
    "options": [
      "Convolutional neural network",
      "Recurrent neural network",
      "Decision tree",
      "k-means network"
    ],
    "correct": "Recurrent neural network",
    "explanation": "RNNs, including LSTMs and GRUs, are designed to handle sequential data.",
    "topic": "Deep Learning"
  },
  {
    "question": "What is backpropagation used for in neural networks?",
    "options": [
      "To initialize weights",
      "To compute weight updates using gradients of the loss function",
      "To normalize the input data",
      "To generate synthetic training data"
    ],
    "correct": "To compute weight updates using gradients of the loss function",
    "explanation": "Backpropagation computes gradients of the loss with respect to each weight and propagates errors backward through the network.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which optimization algorithm is commonly used with neural networks?",
    "options": [
      "Breadth-first search",
      "Gradient descent and its variants",
      "Dijkstra's algorithm",
      "Kruskal's algorithm"
    ],
    "correct": "Gradient descent and its variants",
    "explanation": "Neural networks are typically trained via gradient-based optimization methods like SGD or Adam.",
    "topic": "Deep Learning"
  },
  {
    "question": "What is dropout in deep learning?",
    "options": [
      "A data augmentation technique",
      "A method for scaling learning rates",
      "A regularization technique that randomly disables neurons during training",
      "A way to initialize network weights"
    ],
    "correct": "A regularization technique that randomly disables neurons during training",
    "explanation": "Dropout reduces overfitting by randomly setting some activations to zero during training.",
    "topic": "Deep Learning"
  },
  {
    "question": "In natural language processing, tokenization refers to:",
    "options": [
      "Encrypting text",
      "Splitting text into units such as words or subwords",
      "Removing all punctuation from text",
      "Translating text into another language"
    ],
    "correct": "Splitting text into units such as words or subwords",
    "explanation": "Tokenization breaks a text sequence into tokens that are then processed numerically.",
    "topic": "AI Applications"
  },
  {
    "question": "Which of the following is a typical application of computer vision?",
    "options": [
      "Machine translation between languages",
      "Image classification of medical scans",
      "Speech-to-text transcription",
      "Recommending music playlists"
    ],
    "correct": "Image classification of medical scans",
    "explanation": "Computer vision deals with analysis and understanding of visual data such as images or video.",
    "topic": "AI Applications"
  },
  {
    "question": "Recommendation systems used by services like Netflix or Amazon are usually classified as:",
    "options": [
      "General AI",
      "Narrow AI",
      "Super AI",
      "Reinforcement-only AI"
    ],
    "correct": "Narrow AI",
    "explanation": "Recommender systems are specialized AI systems focused on a specific task: recommending items.",
    "topic": "AI Applications"
  },
  {
    "question": "Chatbots like Siri, Alexa, or Google Assistant are examples of:",
    "options": [
      "Super AI",
      "General AI",
      "Narrow AI",
      "Unsupervised AI"
    ],
    "correct": "Narrow AI",
    "explanation": "They are designed for specific tasks like voice interaction and information retrieval, not general intelligence.",
    "topic": "AI Applications"
  },
  {
    "question": "Which of the following is a common type of recommendation approach?",
    "options": [
      "Rule-based reasoning",
      "Content-based and collaborative filtering",
      "Graph search only",
      "Brute-force search over all products"
    ],
    "correct": "Content-based and collaborative filtering",
    "explanation": "Modern recommenders often use content-based methods and/or collaborative filtering based on user behavior.",
    "topic": "AI Applications"
  },
  {
    "question": "Which type of data labeling is typically needed for supervised image classification?",
    "options": [
      "Labels indicating which class each image belongs to",
      "Labels showing which cluster each image is in",
      "No labels are needed",
      "Labels only for a small random subset of images"
    ],
    "correct": "Labels indicating which class each image belongs to",
    "explanation": "Supervised classification requires knowing the correct class for each training example.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which learning setup is most suitable if you have a very large unlabeled dataset and a small labeled dataset?",
    "options": [
      "Pure supervised learning",
      "Unsupervised learning only",
      "Semi-supervised learning",
      "No learning is possible"
    ],
    "correct": "Semi-supervised learning",
    "explanation": "Semi-supervised learning leverages both labeled and unlabeled data.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "What is transfer learning?",
    "options": [
      "Training a model on multiple GPUs",
      "Transferring labels between datasets",
      "Using a model pre-trained on one task as a starting point for another task",
      "Transferring ownership of a dataset"
    ],
    "correct": "Using a model pre-trained on one task as a starting point for another task",
    "explanation": "Transfer learning reuses knowledge from one task to improve learning on a related task.",
    "topic": "Deep Learning"
  },
  {
    "question": "Which of the following is an example of generative AI?",
    "options": [
      "A model that clusters customers",
      "A model that predicts housing prices",
      "A model that creates realistic images from text prompts",
      "A model that compresses files"
    ],
    "correct": "A model that creates realistic images from text prompts",
    "explanation": "Generative AI models such as diffusion models or GANs can generate new images from textual descriptions.",
    "topic": "Generative AI"
  },
  {
    "question": "Large language models like GPT are primarily trained using:",
    "options": [
      "Supervised learning on labeled sentiment data only",
      "Unsupervised or self-supervised learning on large text corpora",
      "Reinforcement learning only",
      "Purely rule-based systems"
    ],
    "correct": "Unsupervised or self-supervised learning on large text corpora",
    "explanation": "They learn to predict the next token or fill in missing text based on massive unlabeled datasets.",
    "topic": "Generative AI"
  },
  {
    "question": "Which risk is associated with using large language models?",
    "options": [
      "They cannot generalize to new inputs",
      "They always output the same answer",
      "They may generate plausible but incorrect or biased information",
      "They never scale to large datasets"
    ],
    "correct": "They may generate plausible but incorrect or biased information",
    "explanation": "LLMs can produce convincing but factually wrong or biased content, which is a key concern.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "What is explainable AI (XAI) mainly concerned with?",
    "options": [
      "Maximizing the number of hidden layers in models",
      "Making AI systems faster to train",
      "Providing understandable reasons for model predictions",
      "Ensuring AI systems never make mistakes"
    ],
    "correct": "Providing understandable reasons for model predictions",
    "explanation": "Explainable AI aims to make model behavior transparent and interpretable to humans.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Algorithmic bias in AI refers to:",
    "options": [
      "Random noise in the training data",
      "Any error in model predictions",
      "Systematic unfairness in how a model treats different groups",
      "Differences in model accuracy between train and test sets"
    ],
    "correct": "Systematic unfairness in how a model treats different groups",
    "explanation": "Bias arises when models consistently disadvantage certain individuals or groups.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which approach can help reduce unfair bias in a machine learning model?",
    "options": [
      "Ignoring sensitive attributes during evaluation",
      "Carefully balancing the training data across groups",
      "Training only on historical data",
      "Removing the test set"
    ],
    "correct": "Carefully balancing the training data across groups",
    "explanation": "Balanced and representative data can reduce bias learned from skewed historical patterns.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "What is 'human-in-the-loop' learning?",
    "options": [
      "Humans manually execute all predictions",
      "Humans occasionally review and correct model outputs to improve performance",
      "Humans control the power supply of the AI system",
      "Humans are excluded from the decision-making process"
    ],
    "correct": "Humans occasionally review and correct model outputs to improve performance",
    "explanation": "Human-in-the-loop systems incorporate human feedback into the training or decision process.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which of the following is a key principle of responsible AI?",
    "options": [
      "Maximizing accuracy at any cost",
      "Hiding how the model makes decisions",
      "Ensuring fairness, accountability, and transparency",
      "Avoiding any human oversight"
    ],
    "correct": "Ensuring fairness, accountability, and transparency",
    "explanation": "Responsible AI frameworks emphasize ethical and transparent use of AI.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which scenario illustrates a privacy concern in AI applications?",
    "options": [
      "Using public weather data to predict rainfall",
      "Using anonymized medical images without identifiers",
      "Using detailed location and identity data from users without consent",
      "Using synthetic data generated from scratch"
    ],
    "correct": "Using detailed location and identity data from users without consent",
    "explanation": "Collecting and using sensitive personal data without consent is a clear privacy issue.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Why can using historical hiring data to train an AI recruitment model be problematic?",
    "options": [
      "Historical data always has missing values",
      "Historical data cannot be stored digitally",
      "Historical data may contain existing human biases",
      "Historical data is too large for machine learning"
    ],
    "correct": "Historical data may contain existing human biases",
    "explanation": "If past decisions were biased, the model can learn and perpetuate those biases.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which of the following best describes a data pipeline?",
    "options": [
      "A neural network with many layers",
      "A series of steps for collecting, processing, and loading data for analysis or modeling",
      "A physical cable connecting servers",
      "A set of model hyperparameters"
    ],
    "correct": "A series of steps for collecting, processing, and loading data for analysis or modeling",
    "explanation": "Data pipelines automate the flow of data from source to model.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "In an AI project, problem scoping usually comes before:",
    "options": [
      "Evaluating the final model",
      "Collecting and exploring data",
      "Deploying into production",
      "Writing documentation"
    ],
    "correct": "Collecting and exploring data",
    "explanation": "You need to clearly define the problem before deciding what data is needed.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which step commonly comes last in a typical AI project cycle?",
    "options": [
      "Problem scoping",
      "Data acquisition",
      "Model training",
      "Model evaluation and deployment"
    ],
    "correct": "Model evaluation and deployment",
    "explanation": "After scoping, acquiring data, and training models, you evaluate and deploy the best model.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which of the following best describes an AI winter?",
    "options": [
      "A period when AI models outperform humans in most tasks",
      "A period of reduced interest and funding in AI research",
      "A period with too many successful AI startups",
      "A period when AI replaces all manual labor"
    ],
    "correct": "A period of reduced interest and funding in AI research",
    "explanation": "AI winters are periods when progress slows and funding for AI declines due to unmet expectations.",
    "topic": "AI History"
  },
  {
    "question": "Which historic event is often considered the starting point of AI as a formal field?",
    "options": [
      "The launch of the World Wide Web",
      "The Dartmouth Conference in 1956",
      "The first iPhone release",
      "The creation of the first search engine"
    ],
    "correct": "The Dartmouth Conference in 1956",
    "explanation": "The Dartmouth Conference brought together researchers and coined the term 'artificial intelligence'.",
    "topic": "AI History"
  },
  {
    "question": "Which breakthrough showed that AI systems could defeat world champions in complex board games like Go?",
    "options": [
      "IBM Watson on Jeopardy!",
      "Deep Blue vs Kasparov",
      "AlphaGo vs Lee Sedol",
      "A* search algorithm"
    ],
    "correct": "AlphaGo vs Lee Sedol",
    "explanation": "DeepMind's AlphaGo defeated Lee Sedol, demonstrating powerful deep reinforcement learning.",
    "topic": "AI Applications"
  },
  {
    "question": "Which challenge is common in training deep learning models on very large datasets?",
    "options": [
      "Lack of any open-source libraries",
      "Insufficient computational resources and long training times",
      "Inability to use GPUs",
      "Too few model parameters"
    ],
    "correct": "Insufficient computational resources and long training times",
    "explanation": "Large models and datasets require significant compute, making training expensive and time-consuming.",
    "topic": "Deep Learning"
  },
  {
    "question": "What is adversarial example in the context of machine learning?",
    "options": [
      "A random noise image the model ignores",
      "A specially crafted input that causes the model to make a wrong prediction",
      "Any example from the test set",
      "A training example with missing labels"
    ],
    "correct": "A specially crafted input that causes the model to make a wrong prediction",
    "explanation": "Adversarial examples exploit model vulnerabilities by making small perturbations that fool the model.",
    "topic": "AI Security"
  },
  {
    "question": "What is adversarial training used for?",
    "options": [
      "To speed up training",
      "To increase dataset size",
      "To improve robustness by training on adversarial examples",
      "To reduce the number of model parameters"
    ],
    "correct": "To improve robustness by training on adversarial examples",
    "explanation": "Adversarial training exposes the model to adversarial inputs so it learns to resist them.",
    "topic": "AI Security"
  },
  {
    "question": "Why can small stickers or graffiti on traffic signs cause problems for self-driving cars?",
    "options": [
      "Cars cannot detect colors",
      "Cameras stop working in sunlight",
      "The perturbations can cause vision models to misclassify the sign",
      "The sensors shut down when they see text"
    ],
    "correct": "The perturbations can cause vision models to misclassify the sign",
    "explanation": "Adversarial perturbations can cause misclassification, leading to unsafe driving decisions.",
    "topic": "AI Security"
  },
  {
    "question": "Which of the following best describes model drift (or data drift)?",
    "options": [
      "The model size increases during training",
      "The training loss becomes zero",
      "The underlying data distribution changes over time, reducing model performance",
      "The model weights are stored on a different server"
    ],
    "correct": "The underlying data distribution changes over time, reducing model performance",
    "explanation": "When production data changes, models trained on old data may no longer perform well.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which MLOps practice helps detect when a deployed model's performance starts degrading?",
    "options": [
      "Ignoring new data",
      "Disabling logging in production",
      "Monitoring prediction quality and key metrics over time",
      "Training only once and never updating"
    ],
    "correct": "Monitoring prediction quality and key metrics over time",
    "explanation": "Continuous monitoring is essential to notice when models no longer work as expected.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "In reinforcement learning, the signal used to evaluate an action is called:",
    "options": [
      "Label",
      "Loss",
      "Reward",
      "Feature"
    ],
    "correct": "Reward",
    "explanation": "Rewards indicate how good an action was in a given state.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "Which of the following is a typical use case of Q-learning?",
    "options": [
      "Clustering images",
      "Solving maze navigation problems",
      "Predicting house prices",
      "Detecting spam emails"
    ],
    "correct": "Solving maze navigation problems",
    "explanation": "Q-learning learns value estimates for state-action pairs, often applied to navigation tasks.",
    "topic": "Reinforcement Learning"
  },
  {
    "question": "Why might an AI model for medical diagnosis require especially strong explainability?",
    "options": [
      "Because images are always easy to interpret",
      "Because models are never wrong in medicine",
      "Because doctors and patients need to understand and trust the basis for decisions",
      "Because explainability speeds up training"
    ],
    "correct": "Because doctors and patients need to understand and trust the basis for decisions",
    "explanation": "High-stakes decisions require transparency so humans can validate and trust the system.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which of the following is NOT a typical non-functional requirement for an AI system?",
    "options": [
      "Latency of predictions",
      "Fairness across user groups",
      "Model accuracy",
      "User interface color scheme"
    ],
    "correct": "User interface color scheme",
    "explanation": "Accuracy, latency, and fairness are non-functional qualities of the AI system; UI color is unrelated.",
    "topic": "AI Applications"
  },
  {
    "question": "What is one advantage of ensemble methods like random forests?",
    "options": [
      "They always use fewer trees than a single decision tree",
      "They often achieve better performance by combining multiple models",
      "They require no training data",
      "They are always easier to interpret than single trees"
    ],
    "correct": "They often achieve better performance by combining multiple models",
    "explanation": "Ensembles reduce variance and can improve accuracy by aggregating the predictions of many models.",
    "topic": "Supervised Learning"
  },
  {
    "question": "Which term describes the use of AI to generate convincing fake audio or video of real people?",
    "options": [
      "Data anonymization",
      "Deepfake generation",
      "Clustering",
      "Regularization"
    ],
    "correct": "Deepfake generation",
    "explanation": "Deepfakes are synthetic media created using generative models to mimic real individuals.",
    "topic": "Generative AI"
  },
  {
    "question": "Why are deepfakes a concern in the context of elections?",
    "options": [
      "They always improve voter turnout",
      "They have no effect on public opinion",
      "They can be used to spread misinformation about candidates",
      "They only affect internal model metrics"
    ],
    "correct": "They can be used to spread misinformation about candidates",
    "explanation": "Deepfakes may manipulate public opinion by depicting candidates saying or doing things they never did.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "Which of the following best describes 'algorithmic accountability'?",
    "options": [
      "Ensuring humans can be blamed for any error",
      "Ensuring AI systems provide traceable and justifiable decisions",
      "Ensuring models are as complex as possible",
      "Ensuring models train faster than before"
    ],
    "correct": "Ensuring AI systems provide traceable and justifiable decisions",
    "explanation": "Algorithmic accountability focuses on transparency and responsibility in AI decision-making.",
    "topic": "AI Ethics and Explainability"
  },
  {
    "question": "What is an example of a classification label in sentiment analysis?",
    "options": [
      "3.14",
      "\"positive\"",
      "0.567",
      "\"2022-01-01\""
    ],
    "correct": "\"positive\"",
    "explanation": "Sentiment models often use labels such as 'positive', 'neutral', or 'negative'.",
    "topic": "AI Applications"
  },
  {
    "question": "A dataset of customer reviews is labeled with 'angry', 'neutral', and 'happy'. Which type of task is this most likely?",
    "options": [
      "Clustering",
      "Regression",
      "Multi-class classification",
      "Reinforcement learning"
    ],
    "correct": "Multi-class classification",
    "explanation": "There are more than two discrete labels, making this a multi-class classification problem.",
    "topic": "Supervised Learning"
  },
  {
    "question": "What is the main goal when using association rule learning in market basket analysis?",
    "options": [
      "Predicting continuous values",
      "Finding interesting relationships like \"customers who buy X also buy Y\"",
      "Clustering customers into groups",
      "Minimizing training loss"
    ],
    "correct": "Finding interesting relationships like \"customers who buy X also buy Y\"",
    "explanation": "Association rule learning discovers co-occurrence patterns in transactional data.",
    "topic": "AI Applications"
  },
  {
    "question": "In a housing price prediction model, which of the following is most likely an input feature rather than a label?",
    "options": [
      "Selling price",
      "Number of bedrooms",
      "Future interest rate",
      "Prediction error"
    ],
    "correct": "Number of bedrooms",
    "explanation": "Number of bedrooms is an explanatory variable used to predict the label (selling price).",
    "topic": "Regression Models"
  },
  {
    "question": "Which situation describes data leakage?",
    "options": [
      "Using too small a learning rate",
      "Using information in training that will not be available at prediction time",
      "Using only numerical features",
      "Using a large test set"
    ],
    "correct": "Using information in training that will not be available at prediction time",
    "explanation": "Leakage gives the model an unfair advantage and leads to overly optimistic evaluation.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Why is normalization especially important for distance-based algorithms like k-nearest neighbors?",
    "options": [
      "Because they require categorical features",
      "Because distances are sensitive to feature scales",
      "Because normalization reduces overfitting automatically",
      "Because they ignore large features"
    ],
    "correct": "Because distances are sensitive to feature scales",
    "explanation": "Unscaled features with large ranges can dominate distance calculations.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which of the following best describes semi-supervised learning?",
    "options": [
      "Learning without any labels",
      "Learning with all data labeled",
      "Learning from a mix of labeled and unlabeled data",
      "Learning only from rewards"
    ],
    "correct": "Learning from a mix of labeled and unlabeled data",
    "explanation": "Semi-supervised methods exploit small labeled sets and large unlabeled sets together.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "What is a typical reason to use dimensionality reduction techniques like PCA?",
    "options": [
      "To add more features",
      "To create labels automatically",
      "To reduce the number of features while preserving important variance",
      "To increase overfitting"
    ],
    "correct": "To reduce the number of features while preserving important variance",
    "explanation": "Dimensionality reduction simplifies models and can improve performance by removing redundant information.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which of the following would most likely be handled with an unsupervised anomaly detection algorithm?",
    "options": [
      "Classifying images of animals",
      "Detecting unusual network traffic patterns indicating possible cyberattacks",
      "Predicting next month’s sales",
      "Translating text from English to French"
    ],
    "correct": "Detecting unusual network traffic patterns indicating possible cyberattacks",
    "explanation": "Anomaly detection finds outliers that differ significantly from typical patterns.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "In which scenario would k-means clustering be appropriate?",
    "options": [
      "Predicting a customer's exact spending next month",
      "Grouping customers into segments based on their purchase behavior",
      "Classifying emails as spam or not spam",
      "Forecasting temperature over time"
    ],
    "correct": "Grouping customers into segments based on their purchase behavior",
    "explanation": "k-means is used to partition data into k clusters based on similarity.",
    "topic": "Unsupervised Learning"
  },
  {
    "question": "Which statement about labeled data is correct?",
    "options": [
      "Labeled data includes inputs and their associated correct outputs",
      "Labeled data never contains errors",
      "Labeled data is only used in clustering",
      "Labeled data is not needed for supervised learning"
    ],
    "correct": "Labeled data includes inputs and their associated correct outputs",
    "explanation": "Labels provide the ground truth that supervised models learn to predict.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "What is one common challenge when labeling large datasets?",
    "options": [
      "Labels never change over time",
      "Labeling is always automatic",
      "Labeling can be expensive and time-consuming",
      "Labels are not needed for most tasks"
    ],
    "correct": "Labeling can be expensive and time-consuming",
    "explanation": "Human annotation often requires domain expertise and significant effort.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Why might we generate synthetic data for training a model?",
    "options": [
      "To remove privacy constraints from real data",
      "To reduce model complexity",
      "To replace all real data",
      "To avoid evaluating the model"
    ],
    "correct": "To remove privacy constraints from real data",
    "explanation": "Synthetic data can mimic statistical properties of real data without revealing sensitive details.",
    "topic": "Data Preprocessing"
  },
  {
    "question": "Which best describes a linear relationship in data?",
    "options": [
      "The output changes randomly regardless of the input",
      "The output changes proportionally with the input",
      "The output is always constant",
      "The output is categorical"
    ],
    "correct": "The output changes proportionally with the input",
    "explanation": "In a linear relationship, changes in input cause proportional changes in output.",
    "topic": "Regression Models"
  },
  {
    "question": "Which of the following is a sign that a regression model might be underfitting?",
    "options": [
      "Low error on training data and high error on test data",
      "High error on both training and test data",
      "Low error on both training and test data",
      "High error on training data but low error on test data"
    ],
    "correct": "High error on both training and test data",
    "explanation": "Underfitting occurs when the model is too simple to capture the underlying pattern, leading to high error everywhere.",
    "topic": "ML Fundamentals"
  },
  {
    "question": "Which of the following is a typical characteristic of deep learning models compared to traditional machine learning models?",
    "options": [
      "They use fewer parameters",
      "They often require more data and compute resources",
      "They cannot work with images",
      "They are always easier to interpret"
    ],
    "correct": "They often require more data and compute resources",
    "explanation": "Deep networks have many parameters and generally need large datasets and compute.",
    "topic": "Deep Learning"
  },
  {
    "question": "Why are GPUs commonly used for training deep neural networks?",
    "options": [
      "They have larger hard drives",
      "They can perform many parallel numerical operations efficiently",
      "They reduce the need for memory",
      "They guarantee zero training error"
    ],
    "correct": "They can perform many parallel numerical operations efficiently",
    "explanation": "Matrix operations in neural networks map well onto GPUs' parallel architecture.",
    "topic": "Deep Learning"
  },
  {
    "question": "What is a key characteristic of artificial intelligence as described in the course?",
    "options": [
    "Software that only follows explicitly programmed rules",
    "Software that solves problems without any data",
    "Software that solves a problem without explicit human instruction",
    "Software that can only perform numerical calculations"
    ],
    "correct": "Software that solves a problem without explicit human instruction",
    "explanation": "AI is presented as systems that can act intelligently and solve tasks without every rule being hand coded.",
    "topic": "AI Fundamentals"
    },
    {
    "question": "Which of the following best describes the goal of artificial intelligence in this course?",
    "options": [
    "Building machines that exactly copy human biology",
    "Introducing intelligence in machines so they can make decisions and learn",
    "Replacing all traditional software engineering",
    "Eliminating the need for data in computing"
    ],
    "correct": "Introducing intelligence in machines so they can make decisions and learn",
    "explanation": "The course defines AI as adding intelligent decision making and learning capabilities to machines.",
    "topic": "AI Fundamentals"
    },
    {
    "question": "Which example is most clearly an application of AI in daily life?",
    "options": [
    "A calculator performing basic arithmetic",
    "A static website showing the same page to all users",
    "A content recommendation system on a streaming platform",
    "A text editor that only checks spelling with fixed rules"
    ],
    "correct": "A content recommendation system on a streaming platform",
    "explanation": "Recommendation systems are standard examples of real world AI applications that learn from user behavior.",
    "topic": "AI Applications"
    },
    {
    "question": "Which branch of AI is most directly concerned with understanding and generating human language?",
    "options": [
    "Robotics",
    "Computer vision",
    "Natural language processing",
    "Speech synthesis only"
    ],
    "correct": "Natural language processing",
    "explanation": "Natural language processing focuses on understanding and generating human language.",
    "topic": "AI Fundamentals"
    },
    {
    "question": "Which of the following is an example of weak or narrow AI?",
    "options": [
    "A system that can solve any intellectual problem a human can",
    "A chess engine that only plays chess at superhuman level",
    "A robot that understands all human emotions",
    "A machine that autonomously designs other AI systems across domains"
    ],
    "correct": "A chess engine that only plays chess at superhuman level",
    "explanation": "Narrow AI is specialized for a specific task, such as playing chess.",
    "topic": "AI Fundamentals"
    },
    {
    "question": "What is the purpose of the Turing test?",
    "options": [
    "To measure how fast a computer can process data",
    "To decide whether a program is mathematically correct",
    "To test whether a machine's behavior is indistinguishable from a human in conversation",
    "To verify that a robot can walk like a human"
    ],
    "correct": "To test whether a machine's behavior is indistinguishable from a human in conversation",
    "explanation": "The Turing test evaluates whether an interrogator can distinguish a machine from a human via dialogue.",
    "topic": "AI History"
    },
    {
    "question": "According to the history presented in the course, what happened around 1955?",
    "options": [
    "The first industrial robot was built",
    "The term artificial intelligence was coined",
    "The first self driving car was demonstrated",
    "The first generative adversarial network was introduced"
    ],
    "correct": "The term artificial intelligence was coined",
    "explanation": "The term artificial intelligence was coined in the mid 1950s, marking the formal start of the field.",
    "topic": "AI History"
    },
    {
    "question": "Which historical figure is associated with one of the first mechanical calculating machines mentioned in the slides?",
    "options": [
    "Alan Turing",
    "John McCarthy",
    "Blaise Pascal",
    "Geoffrey Hinton"
    ],
    "correct": "Blaise Pascal",
    "explanation": "Blaise Pascal built an early mechanical calculator, an important predecessor to modern computing.",
    "topic": "AI History"
    },
    {
    "question": "Which statement best describes the difference between AI and conventional programming in the slides?",
    "options": [
    "AI removes the need for algorithms entirely",
    "AI systems learn from data instead of being fully specified by rules",
    "Conventional programming cannot use data at all",
    "AI systems never require human input"
    ],
    "correct": "AI systems learn from data instead of being fully specified by rules",
    "explanation": "Traditional software is coded with explicit rules, while AI systems learn patterns from data.",
    "topic": "AI Fundamentals"
    },
    {
    "question": "Which of the following is a common example of AI used in smartphones?",
    "options": [
    "Manual brightness adjustment",
    "Voice assistant that understands spoken commands",
    "Calculator app for arithmetic",
    "Static wallpaper image"
    ],
    "correct": "Voice assistant that understands spoken commands",
    "explanation": "Voice assistants use speech recognition and language understanding, which are AI capabilities.",
    "topic": "AI Applications"
    },
    {
    "question": "According to the slides on designing an AI system, which of the following is an early step in the process?",
    "options": [
    "Deploy the model to production",
    "Choose the cloud provider first",
    "Identify the problem to be solved",
    "Tune hyperparameters"
    ],
    "correct": "Identify the problem to be solved",
    "explanation": "The pipeline starts by clearly defining the problem before collecting data or training models.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "In the daily life of an AI programmer, roughly how much time is spent on data related work such as cleaning, preparing, and labeling?",
    "options": [
    "5 percent",
    "15 percent",
    "50 percent",
    "80 percent"
    ],
    "correct": "80 percent",
    "explanation": "The slides emphasize that the majority of time, around 80 percent, is spent on work with data.",
    "topic": "Data Preprocessing"
    },
    {
    "question": "Which of the following is not listed as a typical data pitfall in the course?",
    "options": [
    "Ignoring seasonality such as holidays and sales events",
    "Failing to handle outliers properly",
    "Lacking business understanding",
    "Using too many GPUs for training"
    ],
    "correct": "Using too many GPUs for training",
    "explanation": "The pitfalls focus on data quality and context, not on the amount of hardware used.",
    "topic": "Data Preprocessing"
    },
    {
    "question": "What is data anonymization?",
    "options": [
    "Removing all missing values from the dataset",
    "Changing or removing personal identifiers so individuals cannot be recognized",
    "Sorting the data by time before training",
    "Adding synthetic noise to all numeric features"
    ],
    "correct": "Changing or removing personal identifiers so individuals cannot be recognized",
    "explanation": "Anonymization removes or alters identifiers to protect individual privacy.",
    "topic": "Data Preprocessing"
    },
    {
    "question": "Which statement best describes synthetic data as introduced in the course?",
    "options": [
    "Data collected only from physical sensors",
    "Artificially generated data that mimics real data distributions",
    "Data that has been fully anonymized",
    "Data collected only from open government portals"
    ],
    "correct": "Artificially generated data that mimics real data distributions",
    "explanation": "Synthetic data is artificially created to resemble real data while protecting privacy or augmenting datasets.",
    "topic": "Data Preprocessing"
    },
    {
    "question": "Which activity is the main goal of data labeling or annotation?",
    "options": [
    "Compressing files to reduce storage",
    "Assigning meaningful tags or labels to raw examples",
    "Encrypting data at rest",
    "Randomly shuffling the dataset"
    ],
    "correct": "Assigning meaningful tags or labels to raw examples",
    "explanation": "Labeling connects inputs to desired outputs, enabling supervised learning.",
    "topic": "Data Preprocessing"
    },
    {
    "question": "How is feature engineering defined in the slides?",
    "options": [
    "Selecting only the largest dataset available",
    "Constructing new features from existing data to improve models",
    "Automatically generating labels for supervised learning",
    "Compressing the number of features into a single value"
    ],
    "correct": "Constructing new features from existing data to improve models",
    "explanation": "Feature engineering creates or transforms variables to give models better signals.",
    "topic": "Data Preprocessing"
    },
    {
    "question": "Which of the following is a reason to use synthetic data according to the course?",
    "options": [
    "To guarantee models never overfit",
    "To avoid doing any data cleaning",
    "To augment limited real data while protecting privacy",
    "To remove the need for feature engineering"
    ],
    "correct": "To augment limited real data while protecting privacy",
    "explanation": "Synthetic data can increase dataset size and reduce privacy risks when real data is scarce or sensitive.",
    "topic": "Data Preprocessing"
    },
    {
    "question": "Which step comes after model training in the typical supervised learning workflow described in the slides?",
    "options": [
    "Data collection",
    "Model deployment and monitoring",
    "Feature scaling",
    "Data labeling"
    ],
    "correct": "Model deployment and monitoring",
    "explanation": "After training and evaluation, models are deployed and then monitored in production.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "Which statement about open datasets like those on Kaggle is consistent with the slides?",
    "options": [
    "They can be used as sources of training data for experiments",
    "They replace the need for private organizational data",
    "They must always be kept secret",
    "They cannot be used for machine learning"
    ],
    "correct": "They can be used as sources of training data for experiments",
    "explanation": "Open datasets are highlighted as useful resources for experimentation and learning.",
    "topic": "Data Preprocessing"
    },
    {
    "question": "How is machine learning defined in the course slides?",
    "options": [
    "Hardware that executes instructions faster than humans",
    "Software that learns and improves from experience without being explicitly programmed",
    "A database technology for storing large amounts of data",
    "A rule based expert system with no data"
    ],
    "correct": "Software that learns and improves from experience without being explicitly programmed",
    "explanation": "The definition emphasizes learning from experience rather than hand coded rules.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "Which type of learning uses labeled input output pairs?",
    "options": [
    "Unsupervised learning",
    "Reinforcement learning",
    "Supervised learning",
    "Self learning without data"
    ],
    "correct": "Supervised learning",
    "explanation": "Supervised learning relies on labeled examples mapping inputs to outputs.",
    "topic": "Supervised Learning"
    },
    {
    "question": "Which example is most appropriate for supervised classification?",
    "options": [
    "Grouping customers into unknown clusters",
    "Predicting if an email is spam or not",
    "Discovering new topics in a collection of documents",
    "Finding low dimensional representations without labels"
    ],
    "correct": "Predicting if an email is spam or not",
    "explanation": "Spam detection is a classic labeled classification problem with discrete classes.",
    "topic": "Supervised Learning"
    },
    {
    "question": "Which task is an example of regression rather than classification?",
    "options": [
    "Predicting whether a customer will churn",
    "Grouping similar news articles",
    "Estimating the price of a house given its features",
    "Detecting spam messages"
    ],
    "correct": "Estimating the price of a house given its features",
    "explanation": "Regression predicts continuous numeric values such as prices.",
    "topic": "Regression Models"
    },
    {
    "question": "What distinguishes clustering from classification in the course slides?",
    "options": [
    "Clustering is supervised and classification is unsupervised",
    "Clustering assigns data to predefined labels",
    "Classification learns from labeled data, clustering finds groups without labels",
    "There is no difference between them"
    ],
    "correct": "Classification learns from labeled data, clustering finds groups without labels",
    "explanation": "Classification uses known labels, while clustering discovers structure in unlabeled data.",
    "topic": "Unsupervised Learning"
    },
    {
    "question": "Which learning paradigm involves an agent interacting with an environment and receiving rewards or penalties?",
    "options": [
    "Supervised learning",
    "Reinforcement learning",
    "Unsupervised learning",
    "Clustering"
    ],
    "correct": "Reinforcement learning",
    "explanation": "Reinforcement learning is based on agents learning through rewards and punishments.",
    "topic": "Reinforcement Learning"
    },
    {
    "question": "In supervised learning, what is the main purpose of splitting data into training, validation, and test sets?",
    "options": [
    "To store data on different servers",
    "To speed up feature engineering",
    "To train, tune, and fairly evaluate the model on unseen data",
    "To increase the amount of labeled data"
    ],
    "correct": "To train, tune, and fairly evaluate the model on unseen data",
    "explanation": "The split supports training, model selection, and unbiased final evaluation.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "Which dataset should be used only once at the very end to estimate the final performance of a model?",
    "options": [
    "Training set",
    "Validation set",
    "Test set",
    "Any subset chosen randomly during training"
    ],
    "correct": "Test set",
    "explanation": "The test set is reserved for the final performance estimate after all tuning decisions.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "Which of the following is the go to method for binary classification mentioned in the slides?",
    "options": [
    "Linear regression",
    "Logistic regression",
    "K means clustering",
    "Mean shift clustering"
    ],
    "correct": "Logistic regression",
    "explanation": "Logistic regression is presented as a standard baseline for binary classification tasks.",
    "topic": "Supervised Learning"
    },
    {
    "question": "In the Titanic dataset example, what is the purpose of using statistics and visualization?",
    "options": [
    "To replace machine learning models",
    "To understand patterns such as survival rates across groups",
    "To encrypt passenger data",
    "To generate synthetic passengers"
    ],
    "correct": "To understand patterns such as survival rates across groups",
    "explanation": "Exploratory analysis helps reveal relationships in the data before modeling.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "What key assumption does the Naive Bayes classifier make?",
    "options": [
    "All classes have equal prior probability",
    "Features are strongly dependent on each other",
    "Features are conditionally independent given the class",
    "Data must be linearly separable"
    ],
    "correct": "Features are conditionally independent given the class",
    "explanation": "Naive Bayes assumes conditional independence of features given the class label.",
    "topic": "Supervised Learning"
    },
    {
    "question": "Bayes theorem describes which of the following?",
    "options": [
    "How to compute distances between data points",
    "The probability of an event based on prior knowledge of related conditions",
    "The learning rate for gradient descent",
    "The architecture of a neural network"
    ],
    "correct": "The probability of an event based on prior knowledge of related conditions",
    "explanation": "Bayes theorem combines prior probabilities with evidence to update beliefs.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "Which is a typical use case of Naive Bayes from the slides?",
    "options": [
    "Image segmentation",
    "Spam detection and text classification",
    "Robot motion planning",
    "Clustering of unlabeled data"
    ],
    "correct": "Spam detection and text classification",
    "explanation": "Naive Bayes is commonly applied to text classification problems like spam filtering.",
    "topic": "Supervised Learning"
    },
    {
    "question": "In the fruits example for Naive Bayes, why can misclassification occur?",
    "options": [
    "Because the algorithm ignores probabilities",
    "Because it assumes features like long, sweet and yellow are independent",
    "Because it cannot handle categorical features",
    "Because it requires images rather than tabular data"
    ],
    "correct": "Because it assumes features like long, sweet and yellow are independent",
    "explanation": "The independence assumption can be unrealistic and lead to wrong predictions in some cases.",
    "topic": "Supervised Learning"
    },
    {
    "question": "According to Machine Learning Yearning, why should development and test sets come from the same distribution?",
    "options": [
    "To guarantee zero training error",
    "To ensure the development set is larger than the training set",
    "So that performance on the development set predicts performance on the test set",
    "To reduce the need for regularization"
    ],
    "correct": "So that performance on the development set predicts performance on the test set",
    "explanation": "If the distributions differ, development performance will not be a good proxy for test performance.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "What is the main reason Andrew Ng recommends having a single number evaluation metric for a project?",
    "options": [
    "To make plots easier to draw",
    "To simplify data collection",
    "To help the team decide quickly which model is better",
    "To ensure models never overfit"
    ],
    "correct": "To help the team decide quickly which model is better",
    "explanation": "A single metric simplifies comparing models and guiding progress.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "Which of the following is a recommended first step when building a new machine learning system according to Machine Learning Yearning?",
    "options": [
    "Spend months designing the perfect architecture before training",
    "Build a simple version quickly and iterate",
    "Collect every possible dataset before writing any code",
    "Tune hyperparameters exhaustively on day one"
    ],
    "correct": "Build a simple version quickly and iterate",
    "explanation": "The book advocates starting with a simple baseline and improving based on data and error analysis.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "What is the purpose of doing error analysis on a development set?",
    "options": [
    "To randomly discard bad examples",
    "To manually relabel the training set",
    "To inspect misclassified examples and decide which ideas are worth trying",
    "To reduce the size of the test set"
    ],
    "correct": "To inspect misclassified examples and decide which ideas are worth trying",
    "explanation": "Error analysis helps prioritize which changes are most likely to improve performance.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "In Machine Learning Yearning, which type of error pattern is associated with underfitting?",
    "options": [
    "High variance and low bias",
    "Low variance and low bias",
    "High bias and low variance",
    "High bias and high variance"
    ],
    "correct": "High bias and low variance",
    "explanation": "Underfitting corresponds to high bias where both training and development errors are high.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "Why does Machine Learning Yearning compare performance to human level performance in some tasks?",
    "options": [
    "Because humans always perform perfectly",
    "Because it provides a useful reference for estimating the Bayes optimal error",
    "Because humans generate the training data",
    "Because humans are cheaper than computation"
    ],
    "correct": "Because it provides a useful reference for estimating the Bayes optimal error",
    "explanation": "Human level performance gives a practical lower bound on achievable error.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "Which technique is generally more effective for reducing high variance or overfitting?",
    "options": [
    "Using a smaller training set",
    "Adding regularization",
    "Increasing model complexity",
    "Reducing the number of features in the development set only"
    ],
    "correct": "Adding regularization",
    "explanation": "Regularization is a standard method to reduce variance by penalizing overly complex models.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "When facing high bias or underfitting, which action is typically recommended in Machine Learning Yearning?",
    "options": [
    "Use a smaller model",
    "Add more regularization",
    "Try a more complex model or train longer",
    "Reduce the size of the training set"
    ],
    "correct": "Try a more complex model or train longer",
    "explanation": "Increasing model capacity or training time can help reduce bias.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "What does a data mismatch problem refer to in Machine Learning Yearning?",
    "options": [
    "Labels are missing for most examples",
    "Training and development or test sets come from different distributions",
    "Models have too many parameters",
    "Features are on different scales"
    ],
    "correct": "Training and development or test sets come from different distributions",
    "explanation": "Data mismatch occurs when the training data does not reflect the real world data the system faces.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "In the context of end to end learning, which of the following is a disadvantage highlighted by Andrew Ng?",
    "options": [
    "It requires very little data",
    "It often needs very large labeled datasets",
    "It cannot be implemented with neural networks",
    "It always improves interpretability"
    ],
    "correct": "It often needs very large labeled datasets",
    "explanation": "End to end systems learn many steps jointly and usually require a lot of labeled data.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "Which is a potential advantage of end to end learning pipelines?",
    "options": [
    "They eliminate all need for optimization",
    "They avoid hand designed intermediate features and components",
    "They guarantee perfect generalization",
    "They make debugging trivial"
    ],
    "correct": "They avoid hand designed intermediate features and components",
    "explanation": "End to end learning can replace manually engineered submodules with learned representations.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "Why does Machine Learning Yearning suggest sometimes weighting different parts of the training set?",
    "options": [
    "To exactly match the test set size",
    "To prioritize more relevant data when training",
    "To speed up GPU computation",
    "To remove the need for a development set"
    ],
    "correct": "To prioritize more relevant data when training",
    "explanation": "Weighting lets you emphasize examples that are more representative of the target distribution.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "What is the optimization verification test in Machine Learning Yearning used for?",
    "options": [
    "Verifying that labels are correct",
    "Checking that the optimization algorithm is working properly",
    "Ensuring the training set is large enough",
    "Measuring how interpretable the model is"
    ],
    "correct": "Checking that the optimization algorithm is working properly",
    "explanation": "The test helps confirm that the learning algorithm can optimize the objective when given enough capacity.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "In a multi component pipeline, what is the purpose of error analysis by parts?",
    "options": [
    "To remove unnecessary components",
    "To attribute errors to individual components of the pipeline",
    "To estimate training time",
    "To compress model parameters"
    ],
    "correct": "To attribute errors to individual components of the pipeline",
    "explanation": "Breaking down errors helps identify which module is limiting overall performance.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "According to Machine Learning Yearning, why is scale in data and computation important for deep learning progress?",
    "options": [
    "It reduces the need for labels",
    "Larger networks and more data often improve performance compared to older algorithms",
    "It makes models more interpretable",
    "It guarantees zero training error"
    ],
    "correct": "Larger networks and more data often improve performance compared to older algorithms",
    "explanation": "The book emphasizes that big data and large models are key drivers of modern deep learning gains.",
    "topic": "ML Fundamentals"
    },
    {
    "question": "In the cat picture startup example, what is the main machine learning problem being solved?",
    "options": [
    "Generating new cat images",
    "Detecting whether an image contains a cat",
    "Clustering users into interest groups",
    "Translating cat sounds to text"
    ],
    "correct": "Detecting whether an image contains a cat",
    "explanation": "The example focuses on supervised learning to classify images as cat or non cat.",
    "topic": "Supervised Learning"
    },
    {
    "question": "What is the main goal of unsupervised learning as introduced in the slides?",
    "options": [
    "Predict a numeric output",
    "Learn how to label new data",
    "Find hidden patterns or structure in unlabeled data",
    "Optimize reward over time"
    ],
    "correct": "Find hidden patterns or structure in unlabeled data",
    "explanation": "Unsupervised learning discovers structure without relying on labeled outputs.",
    "topic": "Unsupervised Learning"
    },
    {
    "question": "K means is best described as what type of algorithm?",
    "options": [
    "Distance based clustering algorithm",
    "Rule based classification algorithm",
    "Linear regression method",
    "Reinforcement learning method"
    ],
    "correct": "Distance based clustering algorithm",
    "explanation": "K means groups points based on distance to cluster centroids.",
    "topic": "Unsupervised Learning"
    },
    {
    "question": "In K means clustering, what is a centroid?",
    "options": [
    "A random outlier removed from the dataset",
    "The center representing a cluster",
    "A label assigned to each data point",
    "A measure of model accuracy"
    ],
    "correct": "The center representing a cluster",
    "explanation": "Each centroid is the representative point around which a cluster is formed.",
    "topic": "Unsupervised Learning"
    },
    {
    "question": "According to the slides, K means typically stops when which condition is met?",
    "options": [
    "The training error becomes zero",
    "All data points are used once",
    "Centroids stop changing or a maximum number of iterations is reached",
    "The user manually stops it"
    ],
    "correct": "Centroids stop changing or a maximum number of iterations is reached",
    "explanation": "Convergence is defined by stable centroids or reaching an iteration limit.",
    "topic": "Unsupervised Learning"
    },
    {
    "question": "Which is not listed as a use of K means in the slides?",
    "options": [
    "Customer segmentation",
    "Document classification",
    "Fraud detection",
    "Training a supervised logistic regression model"
    ],
    "correct": "Training a supervised logistic regression model",
    "explanation": "K means is an unsupervised clustering method and is not used for training logistic regression.",
    "topic": "Unsupervised Learning"
    },
    {
    "question": "Which statement about mean shift clustering is consistent with the course material?",
    "options": [
    "It requires specifying the number of clusters in advance",
    "It locates areas of high data density to form clusters",
    "It only works for time series data",
    "It is a supervised algorithm"
    ],
    "correct": "It locates areas of high data density to form clusters",
    "explanation": "Mean shift is a density based algorithm that finds modes in the data distribution.",
    "topic": "Unsupervised Learning"
    },
    {
    "question": "Which of the following is a general use case of clustering mentioned in the slides?",
    "options": [
    "Predicting tomorrow's stock price",
    "Segmenting customers by behavior",
    "Computing exact causal effects",
    "Translating text between languages"
    ],
    "correct": "Segmenting customers by behavior",
    "explanation": "Clustering is often used to group customers with similar behaviors for marketing and analysis.",
    "topic": "Unsupervised Learning"
    },
    {
    "question": "What is the main difference between K means and density based clustering methods such as those shown in the course?",
    "options": [
    "K means can handle arbitrary shapes and density based methods only handle spheres",
    "K means is supervised and density based methods are not",
    "K means is distance based with a fixed number of clusters, density based methods focus on high density regions",
    "There is no difference"
    ],
    "correct": "K means is distance based with a fixed number of clusters, density based methods focus on high density regions",
    "explanation": "K means uses a fixed k and distances, while density methods detect clusters based on point density.",
    "topic": "Unsupervised Learning"
    },
    {
    "question": "Which type of data is most naturally handled by clustering algorithms in the slides?",
    "options": [
    "Data where group labels are already known",
    "Unlabeled data where we want to discover groupings",
    "Data with only one numeric feature",
    "Data with only categorical outputs"
    ],
    "correct": "Unlabeled data where we want to discover groupings",
    "explanation": "Clustering is used when labels are not available and structure must be inferred.",
    "topic": "Unsupervised Learning"
    },
    {
    "question": "Which of the following best captures the role of unsupervised learning in an AI project?",
    "options": [
    "It always replaces supervised learning",
    "It can be used to explore structure before building supervised models",
    "It only works after the model is deployed",
    "It is only for reinforcement learning tasks"
    ],
    "correct": "It can be used to explore structure before building supervised models",
    "explanation": "Unsupervised learning can reveal clusters or patterns that inform later supervised tasks.",
    "topic": "Unsupervised Learning"
    },
    {
    "question": "How is generative AI defined in the Generative AI lecture?",
    "options": [
    "AI that only classifies existing content",
    "AI that creates new content such as text, images, audio, or other media",
    "AI that manages computer networks",
    "AI that only predicts numbers"
    ],
    "correct": "AI that creates new content such as text, images, audio, or other media",
    "explanation": "Generative AI models are designed to produce new outputs rather than only label inputs.",
    "topic": "Generative AI"
    },
    {
    "question": "What are the two main components of a generative adversarial network?",
    "options": [
    "Encoder and decoder",
    "Generator and discriminator",
    "Actor and critic",
    "Teacher and student"
    ],
    "correct": "Generator and discriminator",
    "explanation": "GANs consist of a generator that creates samples and a discriminator that judges them.",
    "topic": "Generative AI"
    },
    {
    "question": "Which type of data were recurrent neural networks and LSTMs originally the go to models for?",
    "options": [
    "Unordered images",
    "Sequential data such as text or audio",
    "Static tabular data",
    "Three dimensional point clouds only"
    ],
    "correct": "Sequential data such as text or audio",
    "explanation": "RNNs and LSTMs are designed to handle sequences and temporal dependencies.",
    "topic": "Deep Learning"
    },
    {
    "question": "What key innovation does the transformer architecture introduce compared to traditional RNNs?",
    "options": [
    "Removing attention mechanisms",
    "Processing sequences strictly one token at a time",
    "Using attention to process tokens in parallel and handle long range dependencies",
    "Only working with images"
    ],
    "correct": "Using attention to process tokens in parallel and handle long range dependencies",
    "explanation": "Transformers rely on self attention, allowing parallel processing and better long range modeling.",
    "topic": "Deep Learning"
    },
    {
    "question": "What does LLM stand for in the course?",
    "options": [
    "Linear Learning Machine",
    "Layered Logic Module",
    "Large Language Model",
    "Local Logistic Model"
    ],
    "correct": "Large Language Model",
    "explanation": "LLM is the abbreviation used for large language model.",
    "topic": "Generative AI"
    },
    {
    "question": "Which capability is highlighted for GPT 4o in the AI models slides?",
    "options": [
    "It only handles text input",
    "It focuses solely on image generation",
    "It supports fast multimodal interactions including text, images, and real time voice",
    "It is limited to a few languages"
    ],
    "correct": "It supports fast multimodal interactions including text, images, and real time voice",
    "explanation": "GPT 4o is described as a multimodal model that can handle several input and output modalities.",
    "topic": "Generative AI"
    },
    {
    "question": "Which statement about Llama 3.1 405B is correct according to the slides?",
    "options": [
    "It is a small model with fewer than one billion parameters",
    "It was trained on over 15 trillion tokens using thousands of GPUs",
    "It only supports English text",
    "It is not suitable for code generation"
    ],
    "correct": "It was trained on over 15 trillion tokens using thousands of GPUs",
    "explanation": "The slides mention very large scale training in terms of tokens and hardware for this model.",
    "topic": "Generative AI"
    },
    {
    "question": "What is a central focus of Anthropic's Claude 3.5 Sonnet model?",
    "options": [
    "Maximizing speed with no safety considerations",
    "Prioritizing constitutional AI for helpful, harmless, and accurate outputs",
    "Only generating images",
    "Operating exclusively offline"
    ],
    "correct": "Prioritizing constitutional AI for helpful, harmless, and accurate outputs",
    "explanation": "Claude is presented as using constitutional AI principles to align its behavior.",
    "topic": "Generative AI"
    },
    {
    "question": "In the prompt engineering slides, what is a persona?",
    "options": [
    "The user's real identity",
    "A fixed dataset used for training",
    "A role or character the AI is instructed to adopt when responding",
    "A type of evaluation metric"
    ],
    "correct": "A role or character the AI is instructed to adopt when responding",
    "explanation": "A persona is a role description that shapes how the model answers.",
    "topic": "Generative AI"
    },
    {
    "question": "Which statement reflects good prompt engineering practice from the lecture?",
    "options": [
    "Prompts should be vague to test the AI",
    "Prompts should be clear, concise, and aligned with the desired outcome",
    "Prompts should avoid any instructions",
    "Prompts must always be extremely long"
    ],
    "correct": "Prompts should be clear, concise, and aligned with the desired outcome",
    "explanation": "The slides emphasize clarity and specificity in prompts to guide the model.",
    "topic": "Generative AI"
    },
    {
    "question": "What is the purpose of the helpful assistant pattern described in the prompt engineering slides?",
    "options": [
    "To make the AI refuse all user requests",
    "To force the AI to answer in a hostile tone",
    "To guide the AI to respond helpfully and avoid insulting or derogatory language",
    "To optimize GPU usage"
    ],
    "correct": "To guide the AI to respond helpfully and avoid insulting or derogatory language",
    "explanation": "This pattern sets behavioral instructions so the model is polite and constructive.",
    "topic": "AI Ethics and Explainability"
    },
    {
    "question": "In the limitations with AI lecture, what is one reason self driving cars are not yet fully deployed everywhere?",
    "options": [
    "They cannot operate in daylight",
    "They are still not safe enough to drive without human supervision",
    "They cannot use cameras or sensors",
    "They never encounter edge cases"
    ],
    "correct": "They are still not safe enough to drive without human supervision",
    "explanation": "The lecture notes that safety and handling rare situations remain major challenges.",
    "topic": "AI Applications"
    },
    {
    "question": "According to the same lecture, what is a key reason AI in healthcare has not fully replaced radiologists?",
    "options": [
    "AI cannot process images",
    "There is no interest in using AI in medicine",
    "Deploying safe and robust AI systems in health is slower and more complex than expected",
    "AI systems never make mistakes"
    ],
    "correct": "Deploying safe and robust AI systems in health is slower and more complex than expected",
    "explanation": "The slides highlight practical and regulatory difficulties in safely deploying AI in medicine.",
    "topic": "AI Applications"
    },
    {
    "question": "The hype versus reality discussion in the course emphasizes which of the following?",
    "options": [
    "AI has already solved all major real world problems",
    "Many companies find AI hard to implement in practice",
    "Most startups do not claim to use AI",
    "AI requires no data preparation"
    ],
    "correct": "Many companies find AI hard to implement in practice",
    "explanation": "The lecture points out a gap between AI hype and actual successful deployment.",
    "topic": "AI Applications"
    },
    {
    "question": "According to the lecture, what did a survey of European AI startups by a venture capital fund find?",
    "options": [
    "None of them used any AI",
    "40 percent did not appear to be using any AI despite branding",
    "All of them used advanced reinforcement learning",
    "Most relied solely on robotics"
    ],
    "correct": "40 percent did not appear to be using any AI despite branding",
    "explanation": "The survey found that many startups marketed themselves as AI companies without substantial AI use.",
    "topic": "AI Applications"
    },
    {
    "question": "In the current state of AI slides, which type of institution produced nearly 90 percent of notable AI models in 2024?",
    "options": [
    "Individual hobbyists",
    "Government labs",
    "Industry organizations",
    "Universities only"
    ],
    "correct": "Industry organizations",
    "explanation": "The AI Index data shows that most frontier models come from industry rather than academia.",
    "topic": "AI Applications"
    },
    {
    "question": "According to AI Index 2025, what happened to the cost of querying a model that scores like GPT 3.5 on MMLU between November 2022 and October 2024?",
    "options": [
    "It increased from 0.07 dollars to 20 dollars per million tokens",
    "It remained constant at 20 dollars per million tokens",
    "It dropped from 20 dollars to about 0.07 dollars per million tokens",
    "It is unknown"
    ],
    "correct": "It dropped from 20 dollars to about 0.07 dollars per million tokens",
    "explanation": "The report highlights a large decrease in inference costs for GPT 3.5 level performance.",
    "topic": "AI Benchmarks"
    },
    {
    "question": "AI Index 2025 reports that the training compute for notable AI models doubles approximately every how many months?",
    "options": [
    "Five days",
    "Five months",
    "Five years",
    "Fifteen years"
    ],
    "correct": "Five months",
    "explanation": "The compute trend is described as doubling roughly every five months for frontier models.",
    "topic": "AI Benchmarks"
    },
    {
    "question": "According to the report, the carbon emissions from training GPT 4 are approximately how many tons of CO2?",
    "options": [
    "0.01 tons",
    "18 tons",
    "588 tons",
    "5,184 tons"
    ],
    "correct": "5,184 tons",
    "explanation": "The report gives a large emissions estimate for GPT 4, in the thousands of tons of CO2.",
    "topic": "AI Ethics and Explainability"
    },
    {
    "question": "In the same comparison, roughly how many tons of CO2 does the average American emit per year as noted in the report?",
    "options": [
    "1 ton",
    "10 tons",
    "18 tons",
    "100 tons"
    ],
    "correct": "18 tons",
    "explanation": "The report gives this number to contextualize model training emissions against personal emissions.",
    "topic": "AI Ethics and Explainability"
    },
    {
    "question": "AI Index 2025 highlights that the number of AI related patents grew from 3,833 in 2010 to how many in 2023?",
    "options": [
    "12,251",
    "38,330",
    "122,511",
    "1,225,110"
    ],
    "correct": "122,511",
    "explanation": "The report shows strong growth in AI patenting, reaching over one hundred thousand patents in 2023.",
    "topic": "AI Applications"
    },
    {
    "question": "Which country accounts for about 69.7 percent of AI patent grants as of 2023?",
    "options": [
    "United States",
    "China",
    "United Kingdom",
    "Germany"
    ],
    "correct": "China",
    "explanation": "China is reported as holding the majority share of AI patent grants in recent years.",
    "topic": "AI Applications"
    },
    {
    "question": "According to AI Index 2025, global corporate AI investment in 2024 was approximately which amount?",
    "options": [
    "25.2 billion dollars",
    "52.3 billion dollars",
    "252.3 billion dollars",
    "2.52 trillion dollars"
    ],
    "correct": "252.3 billion dollars",
    "explanation": "The report lists corporate AI investment at roughly a quarter of a trillion dollars.",
    "topic": "AI Applications"
    },
    {
    "question": "Private investment in generative AI in 2024 reached roughly which amount?",
    "options": [
    "3.39 billion dollars",
    "33.9 billion dollars",
    "339 billion dollars",
    "3 trillion dollars"
    ],
    "correct": "33.9 billion dollars",
    "explanation": "The report shows tens of billions of dollars specifically going into generative AI.",
    "topic": "AI Applications"
    },
    {
    "question": "In 2024, United States private AI investment was about 109.1 billion dollars. How does this compare to China's private AI investment that year?",
    "options": [
    "About the same",
    "About twice as large",
    "Nearly twelve times larger",
    "Smaller than China's"
    ],
    "correct": "Nearly twelve times larger",
    "explanation": "The report notes that U.S. private investment is almost twelve times that of China.",
    "topic": "AI Applications"
    },
    {
    "question": "AI Index 2025 reports that in 2024, what proportion of surveyed organizations reported using AI?",
    "options": [
    "25 percent",
    "55 percent",
    "71 percent",
    "78 percent"
    ],
    "correct": "78 percent",
    "explanation": "The survey suggests that a large majority of organizations are now using AI in some form.",
    "topic": "AI Applications"
    },
    {
    "question": "The same survey shows that the share of respondents using generative AI in at least one business function increased from 33 percent in 2023 to what in 2024?",
    "options": [
    "40 percent",
    "50 percent",
    "71 percent",
    "90 percent"
    ],
    "correct": "71 percent",
    "explanation": "The report highlights rapid growth in generative AI adoption across business functions.",
    "topic": "AI Applications"
    },
    {
    "question": "Which business function most commonly reported cost savings from AI use, with 49 percent of respondents according to AI Index 2025?",
    "options": [
    "Marketing and sales",
    "Service operations",
    "Supply chain management",
    "Human resources"
    ],
    "correct": "Service operations",
    "explanation": "Service operations is singled out as the area where most respondents see cost benefits from AI.",
    "topic": "AI Applications"
    },
    {
    "question": "In industrial robotics, which country installed about 276,300 industrial robots in 2023, more than the rest of the world combined?",
    "options": [
    "United States",
    "Japan",
    "Germany",
    "China"
    ],
    "correct": "China",
    "explanation": "China is reported as leading the world in new industrial robot installations.",
    "topic": "AI Applications"
    },
    {
    "question": "Collaborative robots represented what share of new industrial robot installations in 2023?",
    "options": [
    "2.8 percent",
    "5 percent",
    "10.5 percent",
    "25 percent"
    ],
    "correct": "10.5 percent",
    "explanation": "The report gives this figure to show the growing but still limited share of collaborative robots.",
    "topic": "AI Applications"
    },
    {
    "question": "AI Index 2025 reports how many AI related incident reports in 2024 in the AI Incidents Database?",
    "options": [
    "23",
    "56",
    "133",
    "233"
    ],
    "correct": "233",
    "explanation": "The number 233 indicates a noticeable volume of documented AI incidents in one year.",
    "topic": "AI Ethics and Explainability"
    },
    {
    "question": "Which trend regarding the data commons is highlighted in the report?",
    "options": [
    "Websites are making more data freely available for AI training",
    "Restrictions on data use increased, with restricted tokens rising to between 20 and 33 percent",
    "All public web data is now unrestricted",
    "Data size is no longer important"
    ],
    "correct": "Restrictions on data use increased, with restricted tokens rising to between 20 and 33 percent",
    "explanation": "The report notes that more web data is being restricted, shrinking the open data commons.",
    "topic": "AI Ethics and Explainability"
    },
    {
    "question": "According to the Foundation Model Transparency Index described in AI Index 2025, average transparency scores among major developers changed from 37 percent in October 2023 to what in May 2024?",
    "options": [
    "40 percent",
    "48 percent",
    "58 percent",
    "80 percent"
    ],
    "correct": "58 percent",
    "explanation": "The index shows some improvement, but transparency remains far from perfect.",
    "topic": "AI Ethics and Explainability"
    },
    {
    "question": "The report notes that many advanced language models, even when trained to be unbiased, still do what?",
    "options": [
    "Show no measurable bias",
    "Exhibit implicit biases such as associating negative terms with certain groups",
    "Cannot answer any social questions",
    "Refuse to generate any content"
    ],
    "correct": "Exhibit implicit biases such as associating negative terms with certain groups",
    "explanation": "Experiments in the report show that models can still reflect harmful social biases.",
    "topic": "AI Ethics and Explainability"
    },
    {
    "question": "Responsible AI research at leading conferences has shown which trend according to AI Index 2025?",
    "options": [
    "It has declined since 2019",
    "It has stayed constant at around 100 papers",
    "It has increased, with accepted papers rising from 992 in 2023 to 1,278 in 2024",
    "It has been banned from major venues"
    ],
    "correct": "It has increased, with accepted papers rising from 992 in 2023 to 1,278 in 2024",
    "explanation": "The report documents growth in the number of responsible AI related publications.",
    "topic": "AI Ethics and Explainability"
    },
    {
    "question": "In science and medicine, what is one highlighted impact of AI models like AlphaFold and ESM3?",
    "options": [
    "They are mainly used for text translation",
    "They advance protein structure prediction and sequencing",
    "They replace all clinical staff",
    "They are used only for marketing"
    ],
    "correct": "They advance protein structure prediction and sequencing",
    "explanation": "These models are cited as breakthroughs in understanding protein structures.",
    "topic": "AI Applications"
    },
    {
    "question": "By 2023, about how many AI enabled medical devices had been authorized by the United States FDA according to AI Index 2025?",
    "options": [
    "6",
    "60",
    "223",
    "2,230"
    ],
    "correct": "223",
    "explanation": "The report lists 223 FDA authorized AI enabled medical devices.",
    "topic": "AI Applications"
    },
    {
    "question": "What do recent studies summarized in AI Index 2025 suggest about AI's impact on worker productivity?",
    "options": [
    "AI consistently reduces productivity",
    "AI has no measurable impact",
    "AI tends to boost productivity and can narrow gaps between low and high skilled workers",
    "AI only benefits the most skilled workers"
    ],
    "correct": "AI tends to boost productivity and can narrow gaps between low and high skilled workers",
    "explanation": "The report reviews multiple studies showing productivity gains and support for less experienced workers.",
    "topic": "AI Applications"
    },
    {
    "question": "On benchmarks like SWE bench, the report notes that AI systems improved from solving about 4.4 percent of coding problems in 2023 to what share in 2024?",
    "options": [
    "10 percent",
    "25 percent",
    "50 percent",
    "71.7 percent"
    ],
    "correct": "71.7 percent",
    "explanation": "This large jump illustrates rapid improvement of AI systems on coding benchmarks.",
    "topic": "AI Benchmarks"
    },
    {
    "question": "According to AI Index 2025, smaller models have become much more capable. Which example illustrates this trend?",
    "options": [
    "GPT 4 being replaced by rule based systems",
    "A 3.8 billion parameter model called Phi 3 mini reaching over 60 percent on MMLU, a level previously achieved by a 540 billion parameter model",
    "Only large models improving on benchmarks",
    "Small models no longer being used"
    ],
    "correct": "A 3.8 billion parameter model called Phi 3 mini reaching over 60 percent on MMLU, a level previously achieved by a 540 billion parameter model",
    "explanation": "The report uses Phi 3 mini as an example of strong performance from a relatively small model.",
    "topic": "AI Benchmarks"
    }
  ]